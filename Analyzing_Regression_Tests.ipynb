{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Python 2.x / 3.x compatibility\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "#import csv\n",
    "import glob as gb\n",
    "\n",
    "#import pathlib\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "from df2gspread import df2gspread as d2g\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 9)\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python import regression_analysis\n",
    "# from imp import reload\n",
    "# reload(regression_analysis)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# This is a RawNBConvert cell, it isn't run unless you switch it to \"Code\"\n",
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse compatibility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat_matrix = regression_analysis.parse_compatibility_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing a new version\n",
    "\n",
    "The compatibility matrix is parsed from its [online location](https://github.com/NREL/OpenStudio/wiki/OpenStudio-Version-Compatibility-Matrix) and is used for looking up E+ versions corresponding to your OpenStudio version.\n",
    "\n",
    "If you are working on a custom develop local build, you don't want to be prompted each time you parse df_files, so you can directly add it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you want to get info from your local build**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_long_version = regression_analysis.test_os_cli('/home/julien/Software/Others/OS-build/Products/openstudio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version, sha = \".\".join(os_long_version.split(\".\")[:3]), os_long_version.split(\".\")[3]\n",
    "\n",
    "# Force a new version (don't want to be prompted each time I parse df_files)\n",
    "new_version = compat_matrix.iloc[0].copy()\n",
    "new_version['OpenStudio'] = version\n",
    "new_version['E+'] = \"8.9.0\"\n",
    "new_version['SHA'] = sha\n",
    "new_version['Released'] = 'TBD'\n",
    "new_version['Has_Docker'] = False\n",
    "\n",
    "compat_matrix = compat_matrix.append(new_version).sort_values('OpenStudio', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** If you want to do it manually **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Force a new version (don't want to be prompted each time I parse df_files)\n",
    "new_version = compat_matrix.iloc[0].copy()\n",
    "new_version['OpenStudio'] = \"2.5.1\"\n",
    "new_version['E+'] = \"8.9.0\"\n",
    "new_version['SHA'] = ''\n",
    "new_version['Released'] = 'TBD'\n",
    "new_version['Has_Docker'] = False\n",
    "\n",
    "compat_matrix = compat_matrix.append(new_version).sort_values('OpenStudio', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the compat matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat_matrix['Has_Docker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oldest versions to have a Docker image\n",
    "compat_matrix[compat_matrix['Has_Docker']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Number of OpenStudio versions within each E+ version\n",
    "compat_matrix.groupby('E+')['OpenStudio'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "compat_matrix.groupby('E+')['OpenStudio'].count().plot(kind='barh', ax=ax)\n",
    "ax.set_xlim(0, compat_matrix.groupby('E+')['OpenStudio'].count().max())\n",
    "ax.set_title('Number of OpenStudio version for each E+ version')\n",
    "ax.set_xlabel('Number of OpenStudio Versions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "# compat_matrix.to_csv('compat_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix permissions and skin down the fuelcell OSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skinning it down is done in the model_tests.rb now\n",
    "help(regression_analysis.cleanup_bloated_osws)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!stat --format '%a' test/fuelcell.osm_2.2.0_out.osw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The permissions stuff is done in the launch docker shell scripts\n",
    "\n",
    "If you want to do it manually\n",
    "\n",
    "Need to do:\n",
    "    \n",
    "    sudo chown -R $USER * \n",
    "    sudo find . -type f -exec chmod 664 {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse out.osw files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from imp import reload\n",
    "reload(regression_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without custom tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = regression_analysis.find_info_osws(compat_matrix=compat_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With custom Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_files = regression_analysis.find_info_osws_with_tags(compat_matrix=compat_matrix, tags_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the test status: Fail/Success/Blank"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from imp import reload\n",
    "reload(regression_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_colors(val):\n",
    "    fmt = ''\n",
    "    s = 'background-color: {}'\n",
    "    if val == 'Fail':\n",
    "        fmt = s.format('#F4C7C3')\n",
    "    elif val == 'N/A':\n",
    "        fmt = s.format('#EDEDED') +\"; color: #ADADAD;\"\n",
    "    elif val == '':\n",
    "        fmt = s.format('#f2e2c1')\n",
    "    return fmt\n",
    "\n",
    "def hover(hover_color=\"#ffff99\"):\n",
    "    return dict(selector=\"tr:hover\",\n",
    "                props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "\n",
    "styles = [\n",
    "    hover(),\n",
    "    dict(selector=\"td\", props=[#(\"font-size\", \"150%\"),\n",
    "                               (\"text-align\", \"center\")]),\n",
    "    dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\")])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataframe \n",
    "# If you get an error, make sure the df_files is up to date by reruning section 3.1 or 3.2 above\n",
    "success = regression_analysis.success_sheet(df_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entire success table"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Output and style entire results\n",
    "(success.style.applymap(background_colors).set_table_styles(styles)\n",
    "          .set_caption(\"Test Success\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for a few tests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only those were some are missing or failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# filt = success[(success == '').any(axis=1) |\n",
    "#                (success == 'Fail').any(axis=1)].index.get_level_values(0).unique().tolist()\n",
    "\n",
    "filt = success['n_fail+missing']>0\n",
    "\n",
    "(success.loc[filt].style\n",
    "          .applymap(background_colors)\n",
    "          .set_table_styles(styles)\n",
    "          .set_caption(\"Test Success\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Filter on a single containing string\n",
    "filt = success.index.get_level_values(0).str.contains('unitary_systems_airloop_and_zonehvac')\n",
    "\n",
    "# Filter on a pattern\n",
    "#filt = success.index.get_level_values(0).str.match(r'(exterior_equipment)|(meters)|(plant_op_schemes)|(avms_temp)')\n",
    "\n",
    "(success.loc[filt].style.applymap(background_colors).set_table_styles(styles)\n",
    "          .set_caption(\"Test Success\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output command to rerun the tests that used to run in the previous version\n",
    "# and now don't\n",
    "torun = success[(success[('8.9.0', '2.4.3')] == 'Success') &\n",
    "                (success[('8.9.0', '2.5.0')] != 'Success')]\n",
    "\n",
    "\n",
    "s = \"openstudio model_tests.rb -n '/\"\n",
    "tests = []\n",
    "for i, (test, ext) in enumerate(torun.index.tolist()):\n",
    "    test_name = \"test_{}_{}\".format(test, ext)\n",
    "    #test_name = \"test_{}\".format(test)\n",
    "    #s += \" --name test_{}_{}\".format(test, ext)\n",
    "    if i < len(torun)-1:\n",
    "        s+='({})|'.format(test_name)\n",
    "    else:\n",
    "        s+='({})'.format(test_name)\n",
    "    tests.append(test_name)\n",
    "\n",
    "s += \"/'\"\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheet = '/EffiBEM&NREL-Regression-Test_Status'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wks_name = 'Test_Status'\n",
    "d2g.upload(success.T.reset_index().T.reset_index(),\n",
    "           gfile=spreadsheet, wks_name=wks_name,\n",
    "           row_names=False, col_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Missing tests: ruby versus osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_impl = regression_analysis.test_implemented_sheet(df_files=df_files, success=success,\n",
    "                                   only_for_mising_osm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_impl[~test_impl['osm']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wks_name = 'Tests_Implemented'\n",
    "d2g.upload(test_impl,\n",
    "           gfile=spreadsheet, wks_name=wks_name,\n",
    "           row_names=True, col_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ouput the total_site_energy (kBTU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu = df_files.applymap(regression_analysis.parse_total_site_energy)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wks_name = 'SiteKBTU'\n",
    "d2g.upload(site_kbtu.T.reset_index().T.reset_index().fillna(''),\n",
    "           gfile=spreadsheet, wks_name=wks_name,\n",
    "           # Skip first row\n",
    "           start_cell='A1',\n",
    "           row_names=False, col_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output the rolling percent difference of total kBTU from one version to the next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu_change = site_kbtu.pct_change(axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Output to google\n",
    "wks_name = 'SiteKBTU_Percent_Change'\n",
    "d2g.upload(site_kbtu.pct_change(axis=1).T.reset_index().T.reset_index().fillna(''),\n",
    "           gfile=spreadsheet, wks_name=wks_name,\n",
    "           row_names=False, col_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site_kbtu_change.loc['pv_and_storage_facilityexcess']\n",
    "site_kbtu_change.loc[site_kbtu_change.index.get_level_values(0).str.contains('flat_plate')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(site_kbtu_change[(site_kbtu_change.abs() > 0.005).any(axis=1)].abs().style\n",
    " .background_gradient(cmap=sns.light_palette(\"red\", as_cmap=True))\n",
    " .format(\"{:.2%}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap > 1% change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_threshold = 1. / 100.0\n",
    "display_threshold = 0.1 / 100.0\n",
    "\n",
    "figname = 'site_kbtu_pct_change_row{}_display{}.png'.format(row_threshold, \n",
    "                                                            display_threshold)\n",
    "\n",
    "print(\"Row threshold = {:.2%}, Cell Display Threshold = {:.2%}\".format(row_threshold, display_threshold))\n",
    "\n",
    "regression_analysis.heatmap_sitekbtu_pct_change(site_kbtu=site_kbtu,\n",
    "                            row_threshold=row_threshold, display_threshold=display_threshold,\n",
    "                            savefig=True, figname=figname,\n",
    "                            show_plot=True, save_indiv_figs_for_ax=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y' - x' = alpha(y-x)\n",
    "y' - y = x - x' = a\n",
    "<=>\n",
    "a = (alpha-1) * (y-x) / 2\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1)\n",
    "plt.show()\n",
    "extent = (ax.get_tightbbox(fig.canvas.renderer)\n",
    "            .transformed(fig.dpi_scale_trans.inverted()))\n",
    "a = (alpha-1)*(extent.ymax-extent.ymin) / 2.0\n",
    "mpl.transforms.Bbox([[extent.xmin, extent.ymin], [extent.xmax, extent.ymax]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap > 0.5% change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "row_threshold  = 0.05 / 100.0\n",
    "display_threshold=0.01 / 100.0\n",
    "\n",
    "figname = 'site_kbtu_pct_change_row{}_display{}.png'.format(row_threshold, \n",
    "                                                            display_threshold)\n",
    "print(\"Row threshold = {:.2%}, Cell Display Threshold = {:.2%}\".format(row_threshold, display_threshold))\n",
    "regression_analysis.heatmap_sitekbtu_pct_change(site_kbtu=site_kbtu,\n",
    "                            row_threshold=row_threshold, display_threshold=display_threshold,\n",
    "                            savefig=True, figname=figname,\n",
    "                            show_plot=True, save_indiv_figs_for_ax=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_diffs = site_kbtu_change.loc[site_kbtu_change[('8.9.0', '2.5.0')].abs() >= 0.0001, '8.9.0']\n",
    "# Sort by abs of 2.4.2\n",
    "new_diffs = new_diffs.loc[new_diffs['2.5.0'].abs().sort_values(ascending=False).index]\n",
    "# new_diffs.to_csv('NewDiffs.csv')\n",
    "new_diffs.style.format(lambda x: '{:.3%}'.format(x) if not np.isnan(x) else '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"_\".join(x) for x in new_diffs[new_diffs['2.4.2'].abs()>= (0.1/100.0)].index.tolist()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Output command to run the ones were we have big diffs\n",
    "torun = new_diffs[new_diffs['2.5.0'].abs()>= (0.1/100.0)]\n",
    "\n",
    "s = \"openstudio model_tests.rb -n '/\"\n",
    "tests = []\n",
    "for i, (test, ext) in enumerate(torun.index.tolist()):\n",
    "    if test == 'unitary_system_performance_multispeed':\n",
    "        continue\n",
    "    test_name = \"test_{}_{}\".format(test, 'osm')\n",
    "    #test_name = \"test_{}\".format(test)\n",
    "    #s += \" --name test_{}_{}\".format(test, ext)\n",
    "    if i < len(torun)-1:\n",
    "        s+='({})|'.format(test_name)\n",
    "    else:\n",
    "        s+='({})'.format(test_name)\n",
    "    tests.append(test_name)\n",
    "\n",
    "s += \"/'\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_diffs[new_diffs['2.5.0'].abs()>= (0.1/100.0)].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference in end use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input a threshold, here 0.5%\n",
    "threshold = 0.5/100.0\n",
    "\n",
    "over_threshold = (site_kbtu.pct_change(axis=1).abs() > threshold).sum(axis=0).to_frame()\n",
    "col = 'Count (ABS(pct_diff) > {:.2%})'.format(threshold)\n",
    "over_threshold.columns = [col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_threshold.replace(0, np.nan).dropna().sort_values(col, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_1 = '2.4.3'\n",
    "version_2 = '2.5.0'\n",
    "\n",
    "\n",
    "all_diffs = {}\n",
    "failed = {}\n",
    "for index, row in  df_files.T.reset_index(level=0, drop=True).T.iterrows():\n",
    "    diff_ok = True\n",
    "    try:\n",
    "        cleaned_end_use_2 = regression_analysis.parse_end_use(row[version_2])\n",
    "        ok2 = True\n",
    "    except:\n",
    "        cleaned_end_use_2 = 'Failed'\n",
    "        diff_ok = False\n",
    "        ok2 = False\n",
    "    try:\n",
    "        cleaned_end_use_1 = regression_analysis.parse_end_use(row[version_1])\n",
    "        ok1 = True\n",
    "    except:\n",
    "        cleaned_end_use_1 = 'Failed'\n",
    "        diff_ok = False\n",
    "        ok1 = False\n",
    "    if diff_ok:\n",
    "        pct_diff = (cleaned_end_use_2 - cleaned_end_use_1) / cleaned_end_use_1\n",
    "        \n",
    "        all_diffs[index] = {version_1: cleaned_end_use_1,\n",
    "                            version_2: cleaned_end_use_2,\n",
    "                            'diff': pct_diff}\n",
    "    else:\n",
    "        failed[index] = {version_1: ok1,\n",
    "                         version_2: ok2}\n",
    "        \n",
    "df_failed = pd.DataFrame(failed).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the ones that changed: False means it fails, True means it worked\n",
    "df_failed[df_failed[version_1] != df_failed[version_2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_diffs = {}\n",
    "for test, d in all_diffs.items():\n",
    "    #dmax = \n",
    "    max_diffs[test] = {'Max': d['diff'].max().max(),\n",
    "                       'Min': d['diff'].min().min(),\n",
    "                       'Total Diff': (d[version_2][('Total', 'kBtu')].sum()\n",
    "                                      - d[version_1][('Total', 'kBtu')].sum()) / d[version_1][('Total', 'kBtu')].sum()}\n",
    "    \n",
    "    \n",
    "df_diffs = pd.DataFrame(max_diffs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diffs[~(df_diffs == 0).all(axis=1)].style.format(\"{:.5%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ('unitary_systems_airloop_and_zonehvac', 'rb')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "\n",
    "fmt = lambda x,pos: '{:.0%}'.format(x)\n",
    "\n",
    "sns.heatmap(all_diffs[test]['diff'].dropna(how='all', axis=0).dropna(how='all', axis=1).abs(),\n",
    "            ax=ax, cmap='YlOrRd',\n",
    "            vmin=0, vmax=1,\n",
    "            cbar_kws={'format': mpl.ticker.FuncFormatter(fmt)},\n",
    "            annot=all_diffs[test]['diff'].dropna(how='all', axis=0).dropna(how='all', axis=1), fmt='.1%')\n",
    "ax.set_title(\"Percent difference in End Use By Fuel for test '{}.{}' between {}\"\n",
    "             \" and {}\".format(test[0], test[1], version_2, version_1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find missing tests: Map tests to Cpp classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grep in ruby and osm tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(ROOT_DIR, 'model/simulationtests/'))\n",
    "\n",
    "# Grep in ruby test for Model:: statements (works on Unix only)\n",
    "grep = !grep \"Model::\" *.rb\n",
    "objs = pd.DataFrame([x.split(':', maxsplit=1 ) for x in grep], columns=['file', 'grepped_line'])\n",
    "\n",
    "# Grep in ruby test for Model:: statements\n",
    "grep_lib = !/bin/grep \"Model::\" ./lib/*.rb\n",
    "objs_lib = pd.DataFrame(grep_lib, columns=['grepped_line'])\n",
    "objs_lib['file'] = 'lib/baseline_model.rb'\n",
    "\n",
    "# Find all Model namespace Classes by getting name from the cpp files\n",
    "os_classes = !ls ~/Software/Others/OpenStudio/openstudiocore/src/model/*.cpp\n",
    "os_classes = [os.path.split(os.path.splitext(p)[0])[1] for p in os_classes]\n",
    "\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object_pat = re.compile(r'OpenStudio::Model::(.*?)\\.new')\n",
    "def parse_model_object(s):\n",
    "    m = model_object_pat.search(s)\n",
    "    if m:\n",
    "        return m.groups()[0]\n",
    "    else:\n",
    "        print('Cannot match {}'.format(s))\n",
    "        return None\n",
    "    \n",
    "objs['ModelObject'] = objs['grepped_line'].apply(parse_model_object)\n",
    "objs_lib['ModelObject'] = objs_lib['grepped_line'].apply(parse_model_object)\n",
    "\n",
    "# Concat both\n",
    "objs = pd.concat([objs, objs_lib])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(objs['ModelObject']) - set(os_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(os_classes) - set(objs['ModelObject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_classes = pd.DataFrame(index=os_classes)\n",
    "df_os_classes['In Ruby Test'] = False\n",
    "df_os_classes = df_os_classes.join(objs.groupby('ModelObject')['file'].apply(list))\n",
    "df_os_classes.loc[df_os_classes['file'].notnull(),\n",
    "                  'file'] = df_os_classes.loc[df_os_classes['file'].notnull(),\n",
    "                                              'file'].apply(np.unique)\n",
    "df_os_classes.loc[df_os_classes['file'].notnull(), 'In Ruby Test'] = True\n",
    "df_os_classes = df_os_classes.rename(columns={'file': 'files'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_classes['In Ruby Test'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_classes['In Ruby Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_os_classes.to_csv('Mapping_ruby_test_to_cpp_classes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comments dict from the google sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df2gspread import gspread2df as g2d\n",
    "\n",
    "spreadsheet = '/EffiBEM&NREL-Regression-Test_Status'\n",
    "wks_name = 'Mapping_ruby_test_to_cpp_classes'\n",
    "\n",
    "df = g2d.download(spreadsheet, wks_name, col_names = True, row_names = True)\n",
    "#comments_dict = df['IsNormal'].to_dict()\n",
    "comments_dict = df.loc[df['IsNormal'] != '', 'IsNormal'].to_dict()\n",
    "comments_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(comments_dict)\n",
    "s = s[s.str.lower().str.contains('added')].str.split(':', expand=True)[1].str.strip().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tot_obj = 0\n",
    "n_tot_tests = 0\n",
    "for index, val in s.reset_index().groupby(1)['index'].apply(list).items():\n",
    "    if index == 'pv_and_storage_facilityexcess.rb':\n",
    "        test = 'pv_and_storage_facilityexcess.rb and pv_and_storage_demandleveling.rb'\n",
    "        n_tot_tests += 1\n",
    "    else:\n",
    "        test = index\n",
    "    n_tot_tests += 1\n",
    "    n_tot_obj += len(val)\n",
    "    print(\"**{}** ({})\".format(test, len(val)))\n",
    "    print()\n",
    "    for x in val:\n",
    "        print(\"* {}\".format(x))\n",
    "    print(\"\\n\")\n",
    "print(\"\\n**Total Added: {} objects in {} tests**\".format(n_tot_obj, n_tot_tests))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "comments_dict = {\n",
    " 'AccessPolicyStore': 'TRUE',\n",
    " 'AdditionalProperties': 'Tested in additional_props.rb',\n",
    " 'AirLoopHVACReturnPlenum': 'TRUE',\n",
    " 'AirLoopHVACSupplyPlenum': 'TRUE',\n",
    " 'AirLoopHVACZoneMixer': 'TRUE',\n",
    " 'AirLoopHVACZoneSplitter': 'TRUE',\n",
    " 'AirToAirComponent': 'TRUE',\n",
    " 'AvailabilityManager': 'Base Class',\n",
    " 'AvailabilityManagerAssignmentList': 'Normal, this is used via plant/airLoop addAvailabilityManager',\n",
    " 'AvailabilityManagerDifferentialThermostat': 'Just Added: plantloop_avms_temp.rb',\n",
    " 'AvailabilityManagerHighTemperatureTurnOff': 'Just Added: plantloop_avms_temp.rb',\n",
    " 'AvailabilityManagerHighTemperatureTurnOn': 'Just Added: plantloop_avms_temp.rb',\n",
    " 'AvailabilityManagerLowTemperatureTurnOff': 'Just Added: plantloop_avms_temp.rb',\n",
    " 'AvailabilityManagerLowTemperatureTurnOn': 'Just Added: plantloop_avms_temp.rb',\n",
    " 'AvailabilityManagerNightCycle': 'availability_managers.rb & airloop_avms.rb via AirLoopHVAC::setNightCycleControlType(\"CycleOnAny\")',\n",
    " 'BoilerSteam': \"I don't think this works because that's the only steam object...\",\n",
    " 'Building': 'TRUE',\n",
    " 'BuildingStory': 'TRUE',\n",
    " 'CentralHeatPumpSystem': 'Just Added: centralheatpumpsystem.rb',\n",
    " 'CentralHeatPumpSystemModule': 'Just Added: centralheatpumpsystem.rb',\n",
    " 'Component': 'TRUE',\n",
    " 'ComponentData': 'TRUE',\n",
    " 'ComponentWatcher': 'TRUE',\n",
    " 'Connection': 'TRUE',\n",
    " 'ConnectorMixer': 'TRUE',\n",
    " 'ConstructionBase': 'TRUE',\n",
    " 'Curve': 'TRUE',\n",
    " 'CurveBicubic': 'TRUE',\n",
    " 'CurveDoubleExponentialDecay': 'TRUE',\n",
    " 'CurveExponentialDecay': 'TRUE',\n",
    " 'CurveExponentialSkewNormal': 'TRUE',\n",
    " 'CurveFanPressureRise': 'TRUE',\n",
    " 'CurveFunctionalPressureDrop': 'TRUE',\n",
    " 'CurveLinear': 'TRUE',\n",
    " 'CurveQuadraticLinear': 'TRUE',\n",
    " 'CurveQuartic': 'TRUE',\n",
    " 'CurveRectangularHyperbola1': 'TRUE',\n",
    " 'CurveRectangularHyperbola2': 'TRUE',\n",
    " 'CurveSigmoid': 'TRUE',\n",
    " 'CurveTriquadratic': 'TRUE',\n",
    " 'DefaultConstructionSet': 'TRUE',\n",
    " 'DefaultScheduleSet': 'TRUE',\n",
    " 'DefaultSubSurfaceConstructions': 'TRUE',\n",
    " 'DefaultSurfaceConstructions': 'TRUE',\n",
    " 'DesignDay': 'TRUE',\n",
    " 'DesignSpecificationZoneAirDistribution': 'Not in ruby API',\n",
    " 'ElectricLoadCenterInverterLookUpTable': 'Just Added: pv_and_storage_facilityexcess.rb',\n",
    " 'ElectricLoadCenterStorageConverter': 'Just Added: pv_and_storage_facilityexcess.rb',\n",
    " 'ElectricLoadCenterStorageSimple': 'Just Added: pv_and_storage_facilityexcess.rb',\n",
    " 'ElectricalStorage': 'TRUE',\n",
    " 'ExteriorFuelEquipment': 'Just Added: exterior_equipment.rb',\n",
    " 'ExteriorFuelEquipmentDefinition': 'Just Added: exterior_equipment.rb',\n",
    " 'ExteriorLoadDefinition': 'Base Class',\n",
    " 'ExteriorLoadInstance': 'Base Class',\n",
    " 'ExteriorWaterEquipment': 'Just Added: exterior_equipment.rb',\n",
    " 'ExteriorWaterEquipmentDefinition': 'Just Added: exterior_equipment.rb',\n",
    " 'Facility': 'TRUE',\n",
    " 'FenestrationMaterial': 'Base class for ShadingMaterial, Glazing, GasLayer',\n",
    " 'FileOperations': 'TRUE',\n",
    " 'FloorplanJSForwardTranslator': 'TRUE',\n",
    " 'FoundationKivaSettings': 'foundation_kiva.rb, via model.getFoundationKivaSettings',\n",
    " 'Gas': 'TRUE',\n",
    " 'GasEquipment': 'Just Added: space_load_instances.rb',\n",
    " 'GasEquipmentDefinition': 'Just Added: space_load_instances.rb',\n",
    " 'Generator': 'TRUE',\n",
    " 'GeneratorMicroTurbine': 'Just Added: generator_microturbine.rb',\n",
    " 'GeneratorMicroTurbineHeatRecovery': 'Just Added: generator_microturbine.rb',\n",
    " 'GeneratorPhotovoltaic': 'Tested for in photovoltaics.rb',\n",
    " 'GenericModelObject': 'TRUE',\n",
    " 'Glazing': 'TRUE',\n",
    " 'HVACComponent': 'TRUE',\n",
    " 'HVACTemplates': 'This is used in most files through the lib/baseline_model.rb',\n",
    " 'HotWaterEquipment': 'Just Added: space_load_instances.rb',\n",
    " 'HotWaterEquipmentDefinition': 'Just Added: space_load_instances.rb',\n",
    " 'Inverter': 'TRUE',\n",
    " 'LayeredConstruction': 'TRUE',\n",
    " 'LifeCycleCost': 'It is tested for LifeCycleParameters.rb',\n",
    " 'LifeCycleCostParameters': 'It is tested for LifeCycleParameters.rb',\n",
    " 'LifeCycleCostUsePriceEscalation': 'It is tested for LifeCycleParameters.rb',\n",
    " 'Loop': 'TRUE',\n",
    " 'Luminaire': 'Not sure how to use it',\n",
    " 'LuminaireDefinition': 'Not sure how to use it',\n",
    " 'Material': 'TRUE',\n",
    " 'MeterCustom': 'Just Added: meters.rb',\n",
    " 'MeterCustomDecrement': 'Just Added: meters.rb',\n",
    " 'Mixer': 'TRUE',\n",
    " 'ModelExtensibleGroup': 'TRUE',\n",
    " 'ModelMerger': 'TRUE',\n",
    " 'ModelObject': 'TRUE',\n",
    " 'ModelObjectList': 'TRUE',\n",
    " 'Node': 'TRUE',\n",
    " 'OpaqueMaterial': 'True, base class',\n",
    " 'OtherEquipment': 'Just Added: space_load_instances.rb',\n",
    " 'OtherEquipmentDefinition': 'Just Added: space_load_instances.rb',\n",
    " 'OutputMeter': 'Just Added: meters.rb',\n",
    " 'ParentObject': 'TRUE',\n",
    " 'PhotovoltaicPerformance': 'Base class',\n",
    " 'PhotovoltaicPerformanceSimple': 'Just Added: pv_and_storage_facilityexcess.rb',\n",
    " 'PlanarSurface': 'TRUE',\n",
    " 'PlanarSurfaceGroup': 'TRUE',\n",
    " 'PlantEquipmentOperationOutdoorDewpoint': 'Just Added: plant_op_schemes_temp.rb',\n",
    " 'PlantEquipmentOperationOutdoorDewpointDifference': 'Just Added: plant_op_schemes_deltatemp.rb',\n",
    " 'PlantEquipmentOperationOutdoorDryBulb': 'Just Added: plant_op_schemes_temp.rb',\n",
    " 'PlantEquipmentOperationOutdoorDryBulbDifference': 'Just Added: plant_op_schemes_deltatemp.rb',\n",
    " 'PlantEquipmentOperationOutdoorRelativeHumidity': 'Just Added: plant_op_schemes_temp.rb',\n",
    " 'PlantEquipmentOperationOutdoorWetBulbDifference': 'Just Added: plant_op_schemes_deltatemp.rb',\n",
    " 'PlantEquipmentOperationRangeBasedScheme': 'Base Class',\n",
    " 'PlantEquipmentOperationScheme': 'Base Class',\n",
    " 'PortList': 'TRUE',\n",
    " 'Relationship': 'TRUE',\n",
    " 'RenderingColor': 'TRUE',\n",
    " 'ResourceObject': 'TRUE',\n",
    " 'RoofVegetation': 'Just Added: roof_vegetation.rb',\n",
    " 'Schedule': 'TRUE',\n",
    " 'ScheduleBase': 'Base Class',\n",
    " 'ScheduleTypeRegistry': 'TRUE',\n",
    " 'ScheduleWeek': 'TRUE',\n",
    " 'ScheduleYear': 'TRUE',\n",
    " 'SetpointManager': 'TRUE',\n",
    " 'Shade': 'TRUE',\n",
    " 'Site': 'TRUE',\n",
    " 'SizingPeriod': 'TRUE',\n",
    " 'SizingPlant': 'TRUE',\n",
    " 'SizingSystem': 'TRUE',\n",
    " 'SizingZone': 'TRUE',\n",
    " 'SkyTemperature': \"Forward translator does nothing, and it doesn't have setters nor getters: https://github.com/jmarrec/OpenStudio/blob/develop/openstudiocore/src/energyplus/ForwardTranslator/ForwardTranslateSkyTemperature.cpp#L42\",\n",
    " 'SolarCollectorPerformanceFlatPlate': 'Added explicit manipulation of object in solar_collector_flat_plate_water.rb',\n",
    " 'Space': 'TRUE',\n",
    " 'SpaceItem': 'TRUE',\n",
    " 'SpaceLoad': 'TRUE',\n",
    " 'SpaceLoadDefinition': 'TRUE',\n",
    " 'SpaceLoadInstance': 'TRUE',\n",
    " 'SpaceType': 'TRUE',\n",
    " 'Splitter': 'TRUE',\n",
    " 'SteamEquipment': 'Just Added: space_load_instances.rb',\n",
    " 'SteamEquipmentDefinition': 'Just Added: space_load_instances.rb',\n",
    " 'StraightComponent': 'Base Class',\n",
    " 'SubSurface': 'TRUE',\n",
    " 'Surface': 'TRUE',\n",
    " 'Thermostat': 'TRUE',\n",
    " 'ThreeJSForwardTranslator': 'TRUE',\n",
    " 'ThreeJSReverseTranslator': 'TRUE',\n",
    " 'UtilityCost_Charge_Block': 'Not Functional in API',\n",
    " 'UtilityCost_Charge_Simple': 'Not Functional in API',\n",
    " 'UtilityCost_Computation': 'Not Functional in API',\n",
    " 'UtilityCost_Qualify': 'Not Functional in API',\n",
    " 'UtilityCost_Ratchet': 'Not Functional in API',\n",
    " 'UtilityCost_Tariff': 'Not Functional in API',\n",
    " 'UtilityCost_Variable': 'Not Functional in API',\n",
    " 'Version': 'TRUE',\n",
    " 'WaterToAirComponent': 'TRUE',\n",
    " 'WaterToWaterComponent': 'TRUE',\n",
    " 'YearDescription': 'TRUE',\n",
    " 'ZoneHVACComponent': 'TRUE',\n",
    " 'ZoneHVACEquipmentList': 'TRUE'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comments.set_index('Test')['IsNormal'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge comments\n",
    "comments = pd.Series(comments_dict, name='IsNormal')\n",
    "df_os_classes = df_os_classes.join(comments)\n",
    "df_os_classes = df_os_classes[['In Ruby Test', 'IsNormal', 'files']]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filt1 = ~df_os_classes['In Ruby Test']\n",
    "filt2 = df_os_classes['IsNormal'].isnull()\n",
    "df_os_classes[filt1 & filt2] # .apply(lambda x: print(x.name), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find objects in the osm tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change dir to the model test directory\n",
    "os.chdir(os.path.join(ROOT_DIR, 'model/simulationtests/'))\n",
    "\n",
    "# Compile a regex\n",
    "os_class_pattern = re.compile(r'OS:(.*?),')\n",
    "\n",
    "# Initialize a column of empty lists\n",
    "df_os_classes['osms'] = np.empty((len(df_os_classes), 0)).tolist()\n",
    "\n",
    "# Loop on all osms, and find OS objects\n",
    "for osm_path in gb.glob('*.osm'):\n",
    "    with open(osm_path) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        m = os_class_pattern.match(line)\n",
    "        if m:\n",
    "            classname = m.groups()[0].replace(':','')\n",
    "            if classname in df.index:\n",
    "                df_os_classes.loc[classname, 'osms'].append(osm_path)\n",
    "                \n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_classes.loc[df_os_classes['osms'].apply(len) == 0, 'osms'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt1 = ~df_os_classes['In Ruby Test']\n",
    "filt2 = df_os_classes['IsNormal'].isnull()\n",
    "filt3 = df_os_classes['osms'].isnull()\n",
    "df_os_classes[filt1 & filt2 & filt3] # .apply(lambda x: print(x.name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ruby = df_os_classes['In Ruby Test']\n",
    "in_ruby.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_normal = df_os_classes['IsNormal'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_osm = df_os_classes['osms'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(in_ruby | is_normal).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(in_ruby | is_normal | in_osm).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_os_classes.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload to Google"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "spreadsheet = '/EffiBEM&NREL-Regression-Test_Status'\n",
    "wks_name = 'Mapping_ruby_test_to_cpp_classes'\n",
    "d2g.upload(df_os_classes.fillna(''),\n",
    "           gfile=spreadsheet, wks_name=wks_name,\n",
    "           row_names=True, col_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test convergence of OSMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the same in.OSW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_N_TIMES = 5\n",
    "START_AT=5\n",
    "OS_CLI='openstudio'\n",
    "# OS_CLI='ruby'\n",
    "OS_CLI = '/home/julien/Software/Others/OS-build/Products/openstudio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from shutil import copyfile\n",
    "\n",
    "# Modify to suit your needs. You should have run the model_tests.rb with this\n",
    "# test first, so that the in.osw etc exists first...\n",
    "os.chdir(os.path.join(ROOT_DIR, 'testruns/evaporative_cooling.osm/'))\n",
    "\n",
    "r = {}\n",
    "o = {}\n",
    "e = {}\n",
    "for i in range(START_AT, START_AT + RUN_N_TIMES):\n",
    "    process = subprocess.Popen([OS_CLI, 'run', '-w', 'in.osw'], shell=False,\n",
    "                           stdout=subprocess.PIPE, \n",
    "                           stderr=subprocess.PIPE)\n",
    "\n",
    "    # wait for the process to terminate\n",
    "    out, err = process.communicate()\n",
    "    o[i] = out\n",
    "    e[i] = err\n",
    "    errcode = process.returncode\n",
    "    r[i] = regression_analysis.parse_total_site_energy('out.osw')\n",
    "    print(\"{} - {:,.0f}\".format(i, r[i]))\n",
    "    # Copy idf file\n",
    "    idf_path = os.path.abspath('./run/in.idf')\n",
    "    copyfile(idf_path, os.path.abspath('./run_{}.idf'.format(i)))\n",
    "    \n",
    "# Say to user\n",
    "if regression_analysis.platform.system() == 'Linux':\n",
    "    !echo \"THIS IS DONE\" | espeak\n",
    "\n",
    "os.chdir(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    result = pd.concat([result, pd.Series(r)])\n",
    "except:\n",
    "    result = pd.Series(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ((result - result.iloc[0]) / result.iloc[0]).plot(kind='bar')\n",
    "def fmt(x, pos): return '{:.0%}'.format(x)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(fmt))\n",
    "ax.set_title('% change compared to first run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare With Custom Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Sim Tests N Times with Custom Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLATFORM = 'Ubuntu'\n",
    "PLATFORM = None\n",
    "\n",
    "N = 5\n",
    "START_AT = 1\n",
    "# Override if you have only run N times before, and do not want to override\n",
    "# START_AT = 10\n",
    "\n",
    "# Save idf file next to out.osw? \n",
    "# Useful for checking IDF diffs for ruby tests that are unstable\n",
    "SAVE_IDF=False\n",
    "\n",
    "# Filter to pass to model_tests.rb. Input NONE for all tests\n",
    "REGRESSION_TEST_FILTER = None\n",
    "\n",
    "# Override examples:\n",
    "# REGRESSION_TEST_FILTER = '(test_absorption_chillers_rb)|(test_additional_props_rb)|(test_air_chillers_rb)|(test_air_terminals_rb)|(test_airloop_and_zonehvac_rb)|(test_airterminal_cooledbeam_rb)|(test_autosize_hvac_rb)|(test_centralheatpumpsystem_rb)|(test_coolingtowers_rb)|(test_dist_ht_cl_rb)|(test_dsn_oa_w_ideal_loads_rb)|(test_dual_duct_rb)|(test_ducts_and_pipes_rb)|(test_ems_rb)|(test_evaporative_cooling_rb)|(test_exterior_equipment_rb)|(test_fan_on_off_rb)|(test_fuelcell_rb)|(test_generator_microturbine_rb)|(test_headered_pumps_rb)|(test_hightemprad_rb)|(test_humidity_control_rb)|(test_interior_partitions_rb)|(test_lowtemprad_constflow_rb)|(test_lowtemprad_electric_rb)|(test_lowtemprad_varflow_rb)|(test_multi_stage_rb)|(test_plant_op_deltatemp_schemes_rb)|(test_plantloop_avms_temp_rb)|(test_plenums_rb)|(test_pv_and_storage_demandleveling_rb)|(test_pv_and_storage_facilityexcess_rb)|(test_roof_vegetation_rb)|(test_solar_collector_flat_plate_water_rb)|(test_space_load_instances_rb)|(test_surface_properties_rb)|(test_unitary_system_performance_multispeed_rb)|(test_vrf_rb)|(test_water_heaters_rb)|(test_zone_control_contaminant_controller_rb)|(test_zone_fan_exhaust_rb)'\n",
    "# REGRESSION_TEST_FILTER = 'centralheatpumpsystem_osm'\n",
    "# REGRESSION_TEST_FILTER = 'fourpipebeam'\n",
    "# REGRESSION_TEST_FILTER = 'somethingthatdoesntexistfortesting'\n",
    "\n",
    "# If you need to hardset the E+ executable path, otherwise leave as None\n",
    "ENERGYPLUS_EXE_PATH = None\n",
    "# ENERGYPLUS_EXE_PATH = '/home/julien/Software/Others/OS-build/EnergyPlus-8.9.0-40101eaafd-Linux-x86_64/EnergyPlus-8-9-0/energyplus-8.9.0'\n",
    "\n",
    "# Path to your cli, if use system ruby make sure it's setup correctly via openstudio.rb\n",
    "OS_CLI = '/home/julien/Software/Others/OS-build2/Products/openstudio-2.4.3'\n",
    "OS_CLI = 'ruby'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regression_analysis.test_stability(os_cli=OS_CLI, test_filter=REGRESSION_TEST_FILTER,\n",
    "               run_n_times=N, start_at=START_AT,\n",
    "               save_idf=SAVE_IDF,\n",
    "               energyplus_exe_path=ENERGYPLUS_EXE_PATH,\n",
    "               platform_name=PLATFORM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Custom-tagged files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = regression_analysis.find_info_osws_with_tags(compat_matrix=None,\n",
    "                                                        tags_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = regression_analysis.success_sheet(df_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = success['n_fail+missing']>0\n",
    "\n",
    "(success.loc[filt].style\n",
    "          .applymap(background_colors)\n",
    "          .set_table_styles(styles)\n",
    "          .set_caption(\"Test Success\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First filter only tests that have some variations in site kBTU\n",
    "\n",
    "I check for tests where the min accross runs isn't equal to the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu = df_files.applymap(regression_analysis.parse_total_site_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_analysis.heatmap_sitekbtu_pct_change(site_kbtu=site_kbtu, row_threshold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to our version of interest, drop rows with all nan\n",
    "site_kbtu_this_version = site_kbtu['8.9.0']['2.4.4'].dropna(how='all')\n",
    "\n",
    "# Keep only the custom tagged ones\n",
    "# site_kbtu_this_version = site_kbtu_this_version[[x for x in site_kbtu_this_version.columns if x in keep_only_runs]]\n",
    "\n",
    "# Filter on rows where the min is not the max\n",
    "site_kbtu_this_version = site_kbtu_this_version[site_kbtu_this_version.apply(lambda row: min(row) != max(row), axis=1)]\n",
    "\n",
    "# Make a multiindex \n",
    "site_kbtu_this_version.columns = pd.MultiIndex.from_tuples([x.split('_') for x in site_kbtu_this_version.columns],\n",
    "                                                 names=['Platform', 'Run'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these tests where we have variations, we can visualize the deviation each run Platform/run using a boxplox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "site_kbtu_this_version.boxplot(ax=ax, grid=False)\n",
    "ax.set_title('Boxplot of tests that have variations, by platform and run')\n",
    "ax.set_ylabel('Total site kBTU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check biggest differences by looking at CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, I calculate the coefficient of variation ($CV$) for each test = standard deviation ($\\sigma$) divided by mean ($\\mu$)\n",
    "\n",
    "$$CV = \\frac{\\sigma}{\\mu}$$\n",
    "\n",
    "I then use a set tolerance to filter out tests that have a CV that isn't above or equal to the tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of variation: standard deviation divided by mean\n",
    "cv = site_kbtu_this_version.std(axis=1) / site_kbtu_this_version.mean(axis=1)\n",
    "cv.name = 'Coefficient of Variation'\n",
    "cv = cv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.sort_values(ascending=False).to_frame().style.format('{:.5%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tol = 0.00001\n",
    "print(\"Setting CV Tolerance to {:.3%}\".format(cv_tol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_palette('Set2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu_this_version.loc[('centralheatpumpsystem', 'rb')].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu_this_version.loc[('centralheatpumpsystem', 'rb')].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = cv[cv >= cv_tol].sort_values(ascending=True).plot(kind='barh', figsize=(16,9))\n",
    "# Or Plot all\n",
    "\n",
    "toplot = cv.sort_values(ascending=True)\n",
    "toplot.index = [\"_\".join(x) for x in toplot.index]\n",
    "\n",
    "ax = toplot.plot(kind='barh', figsize=(16,9))\n",
    "vals = ax.get_xticks()\n",
    "ax.set_xticklabels(['{:3.4f}%'.format(x*100) for x in vals])\n",
    "ax.set_title('Coefficient of Variation for tests that are above cv_tol={:.3%}'.format(cv_tol))\n",
    "\n",
    "for i, rect in enumerate(ax.patches):\n",
    "    label = ax.get_yticklabels()[i].get_text() \n",
    "    val = toplot[i]\n",
    "    ax.annotate(\"{:.5%}\".format(val), \n",
    "                xy=(rect.get_x()+rect.get_width(), rect.get_y()+rect.get_height()/2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the same tests, we can visualize the total site kBTU for each:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "site_kbtu_this_version.reindex(index=cv[cv >= cv_tol].index).plot(kind='bar', ax=ax)\n",
    "ax.set_title('Total site kBTU for tests that are above the CV tolerance')\n",
    "ax.set_ylabel('Total Site kBTU')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size: 40px; color:red;\">ANYTHING PAST THIS POINT NEEDS CLEANING</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Could Ruby test just be unstable regardless of platform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) First,  **the big differences are in the ruby tests mostly** (except 2.). I've mentionned already that I fixed a bunch of instabilities in the ruby tests, but there are some I couldn't fix yet: **could the ruby tests in question just be unstable regardless of platform?**\n",
    "\n",
    "I plot the entire heatmap (all OS version) of these tests which have a CV >= cv_tol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = site_kbtu.reindex(index=cv[cv >= cv_tol].index)\n",
    "toplot = toplot[[x for x in toplot.columns if x[2] in ([''] + keep_only_runs)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_analysis.heatmap_sitekbtu_pct_change(site_kbtu=toplot,\n",
    "                            row_threshold=0.0000, display_threshold=0.0001, \n",
    "                            savefig=False, show_plot=True, figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tests are unstable regardless of platform:\n",
    "    \n",
    "* airloop_and_zonehvac.rb\n",
    "* evaporative_cooling.rb\n",
    "* surface_properties.rb \n",
    "* unitary_system_performance_multispeed.rb (edited)\n",
    "\n",
    "The big unknown is **what the heck happened in Windows Run 1 for unitary_vav_bypass**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One OSM test produces different results on different platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "2) One very important exception to (1) above is the `evaporative_cooling.osm` test: **seems to be stable on both platform, but it doesn't have the same numbers on Ubuntu versus windows! Further investigation is warranted.**\n",
    "\n",
    "Note: You might say it's hard to tell if the OSM is stable on a given platform with two runs. I ran it 10 times on Ubuntu, and it is stable.\n",
    "\n",
    "    count    1.000000e+01\n",
    "    mean     7.632714e+06\n",
    "    std      9.817002e-10\n",
    "    min      7.632714e+06\n",
    "    25%      7.632714e+06\n",
    "    50%      7.632714e+06\n",
    "    75%      7.632714e+06\n",
    "    max      7.632714e+06\n",
    "    dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run N more times on a given machine to have more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"'/\"\n",
    "\n",
    "torun = (cv[cv >= cv_tol].index.tolist())\n",
    "\n",
    "for i, (test, ext) in enumerate(torun):\n",
    "    test_name = \"test_{}_{}\".format(test, ext)\n",
    "    #test_name = \"test_{}\".format(test)\n",
    "    #s += \" --name test_{}_{}\".format(test, ext)\n",
    "    if i < len(torun)-1:\n",
    "        s+='({})|'.format(test_name)\n",
    "    else:\n",
    "        s+='({})'.format(test_name)\n",
    "\n",
    "s += \"/'\"\n",
    "print(\"ruby model_tests.rb -n {}\".format(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload with more runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_files = regression_analysis.find_info_osws_with_tags(compat_matrix=compat_matrix)\n",
    "subset_files = df_files[[x for x in df_files.columns\n",
    "                         if x[1] == '2.4.1' \n",
    "                         #and x[2] != 'Ubuntu_run2'\n",
    "                        ]]\n",
    "# Keep only those that I run more than twice\n",
    "subset_files = subset_files.loc[subset_files[('8.8.0', '2.4.1', 'Ubuntu_run3')].notnull()]\n",
    "\n",
    "# Parse site_kbtu\n",
    "site_kbtu = subset_files.applymap(regression_analysis.parse_total_site_energy)\n",
    "\n",
    "# Restrict to our version of interest, drop rows with all nan\n",
    "site_kbtu_241 = site_kbtu['8.8.0']['2.4.1'].dropna(how='all')\n",
    "\n",
    "# Keep only the custom tagged ones\n",
    "site_kbtu_241 = site_kbtu_241[[x for x in site_kbtu_241.columns if x != '']]\n",
    "\n",
    "# Make a multiindex \n",
    "site_kbtu_241.columns = pd.MultiIndex.from_tuples([x.split('_') for x in site_kbtu_241.columns],\n",
    "                                                 names=['Platform', 'Run'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_kbtu_241.groupby(level='Platform', axis=1).mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_from_pct_diff(toplot, display_threshold=0.001, \n",
    "                          title=None):\n",
    "    # Prepare two custom cmaps with one single color\n",
    "    grey_cmap = mpl.colors.ListedColormap('#f7f7f7')\n",
    "    green_cmap = mpl.colors.ListedColormap('#f0f7d9')\n",
    "\n",
    "\n",
    "    w = 16\n",
    "    h = w * toplot.shape[0] / (3 * toplot.shape[1])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(w, h))\n",
    "\n",
    "    # Reserve 1.5 inches at bottom for explanation\n",
    "    #fig.subplots_adjust(bottom=1.5/h)\n",
    "\n",
    "    # Same as: fmt = lambda x,pos: '{:.1%}'.format(x)\n",
    "    def fmt(x, pos): return '{:.1%}'.format(x)\n",
    "\n",
    "\n",
    "    # Plot with colors, for those that are above the display_threshold\n",
    "    sns.heatmap(toplot.abs(), mask=toplot.abs() <= display_threshold,\n",
    "                ax=ax, cmap='YlOrRd',  # cmap='Reds', 'RdYlGn_r'\n",
    "                vmin=0, vmax=0.5,\n",
    "                cbar_kws={'format': mpl.ticker.FuncFormatter(fmt)},\n",
    "                annot=toplot, fmt='.2%', linewidths=.5)\n",
    "\n",
    "    # Plot a second heatmap on top, only for those that are below\n",
    "    sns.heatmap(toplot, mask=((toplot.abs() > display_threshold) |\n",
    "                              (toplot.abs() == 0)),\n",
    "                cbar=False,\n",
    "                annot=True, fmt=\".4%\", annot_kws={\"style\": \"italic\"},\n",
    "                ax=ax, cmap=grey_cmap)\n",
    "\n",
    "    # Plot a third heatmap on top, only for those that are zero,\n",
    "    # no annot just green\n",
    "    sns.heatmap(toplot, mask=(toplot.abs() != 0),\n",
    "                cbar=False,  # linewidths=.5, linecolor='#cecccc',\n",
    "                annot=False,\n",
    "                ax=ax, cmap=green_cmap)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % from the mean siteKBTU of the test\n",
    "toplot = ((site_kbtu_241.T - site_kbtu_241.T.mean())/(site_kbtu_241.T.mean())).T\n",
    "\n",
    "heatmap_from_pct_diff(toplot, title='Percentage difference from mean of test (both_versions)',\n",
    "                     display_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % from the mean siteKBTU of the test\n",
    "mean_ubuntu = site_kbtu_241['Ubuntu'].mean(axis=1)\n",
    "toplot = ((site_kbtu_241.T - mean_ubuntu)/(mean_ubuntu)).T\n",
    "\n",
    "heatmap_from_pct_diff(toplot, title='Percentage difference from mean of test for Ubuntu platform',\n",
    "                     display_threshold=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miscellaneous helper scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = gb.glob('./test/plant_op_schemes_*')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at one cleaned out.osw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls test/*generator*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = regression_analysis.load_osw('test/generator_microturbine.rb_2.0.4_out.osw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename out.oswS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.mkdir('test/Windows')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "for f in gb.glob('test/*_2.4.1_out.osw'):\n",
    "    #outpath = '../model/simulationtests/'\n",
    "    #dst_path = os.path.join(outpath, f.replace('.rb_2.1.1', '') )\n",
    "    dst_path = f.replace('2.4.1_out', '2.4.1_out_Windows_run1').replace('test/', 'test/Windows/')\n",
    "    print(dst_path)\n",
    "    os.rename(f, dst_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for f in gb.glob('test/*2.4.1_out_Windows_run1.osw'):\n",
    "    dst_path  = f.replace('test/', 'test/Windows/')\n",
    "    os.rename(f, dst_path)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for f in gb.glob('test/Windows/*'):\n",
    "    os.rename(f, f.replace('run1', 'run2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zip custom tagged files for sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all tagged runs into a 'Tagged' directory for manual zipping\n",
    "os.mkdir('test/Tagged')\n",
    "for f in gb.glob('test/*out_*.osw'):\n",
    "    print(f)\n",
    "    dst_path  = f.replace('test/', 'test/Tagged/')\n",
    "    copyfile(f, dst_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip in one go...\n",
    "import zipfile\n",
    "import glob as gb\n",
    "with zipfile.ZipFile(\"Tagged.zip\", \"w\") as z:\n",
    "    for f in gb.glob('test/*out_*.osw'):\n",
    "        z.write(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify it worked\n",
    "z = zipfile.ZipFile(\"Tagged.zip\")\n",
    "z.printdir()\n",
    "z.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "810px",
    "left": "0px",
    "right": "1519px",
    "top": "111px",
    "width": "336px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
