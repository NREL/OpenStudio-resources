{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style='font-size: 24px; text-align: center;'>Foreword</p>\n",
    "\n",
    "<div style='font-size:16px;'>**This notebook has two big parts:**\n",
    "\n",
    "<ul>\n",
    "  <li>**Part 1:** aims to transition all regression tests from one E+ version to the next, and allows you to run each test in both the old and the new version\n",
    "    <ul>\n",
    "      <li>These will take quite some time to run (about 1hr to run the tests in the OLD OpenStudio version, transition the IDFs to the new E+ version and run them, and run the tests in the NEW OpenStudio Version, based on almost 200 files currently)</li>\n",
    "      <li>By default it will just copy over the SQL from the regression test to place in OLD_DIR, but if you want to force rerun the IDF in the old E+ version you can.</li>\n",
    "      <li>At the end of Part 1, you will have three CSV files, one per version, with the site KBTUs for each test. And you also have an organized tree of VERSION/TEST_NAME/ output directories that have the SQL files we will use for sections 6+.</li>\n",
    "    </ul>  \n",
    "  </li>\n",
    "  <li>**Part 2:** aims to analyze the differences between versions\n",
    "    <ul>\n",
    "      <li>Section 3.1 just re-queries all SQL file (or you can reload the three CSV files) to highlight the tests with the biggest site KBTU differences</li>\n",
    "      <li>Section 3.2 provides a high-level interface that only requires to pass a test name and it will query the relevant SQL files and produce visualization (tables, grouped bar charts, and heatmaps) to analyze where differences may be coming from</li>\n",
    "    </ul>\n",
    "    If you have already run Part 1 successfully once, you only need to run Section 1. and you can jump to Part 2 directly.\n",
    "  </li>\n",
    "     \n",
    "</div> \n",
    "\n",
    "----\n",
    "\n",
    "**Note**\n",
    "\n",
    "* It might be a good idea to monitor your system after each big tasks to ensure you don't have processes that are still hanging. It happened to me for intersection test for eg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Python 2.x / 3.x compatibility\n",
    "from __future__ import division, print_function\n",
    "\n",
    "#Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "#import csv\n",
    "import glob as gb\n",
    "\n",
    "#import pathlib\n",
    "\n",
    "import datetime\n",
    "import sqlite3\n",
    "\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "\n",
    "import tqdm\n",
    "import pathlib\n",
    "\n",
    "from ipywidgets import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "import shlex\n",
    "\n",
    "# from df2gspread import df2gspread as d2g\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (16, 9)\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Args\n",
    "\n",
    "These should match your actual installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDF_DIR = os.getcwd()\n",
    "IDF_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the OpenStudio-resources/testruns/ directory\n",
    "# TESTRUNS_DIR = '/home/julien/Software/Others/OpenStudio-resources/testruns/'\n",
    "TESTRUNS_DIR = os.path.abspath('../testruns')\n",
    "OS_RES_DIR = os.path.abspath('..')\n",
    "\n",
    "EPLUS_OLD_VERSION = '8.8.0'\n",
    "OS_OLD_VERSION = '2.4.2'\n",
    "\n",
    "EPLUS_NEW_VERSION = '8.9.0'\n",
    "OS_NEW_VERSION = '2.4.3'\n",
    "\n",
    "TRANSITION_CLI_DIR = '/home/julien/Software/Others/EnergyPlus-build/Products'\n",
    "# For some reason this one doesn't work\n",
    "# TRANSITION_CLI_DIR = '/home/julien/Software/Others/OS-build2/EnergyPlus-8.9.0-1c5ba897d1-Linux-x86_64/EnergyPlus-8-9-0/PreProcess/IDFVersionUpdater/'\n",
    "\n",
    "# Force a given number of parallel process \n",
    "# (defaults to nproc - 2, leaving one physical core free if you have hyperthreading)\n",
    "N = None\n",
    "WEATHER_FILE= os.path.join(IDF_DIR, 'USA_IL_Chicago-OHare.Intl.AP.725300_TMY3.epw')\n",
    "\n",
    "# Path to EnergyPlus application & idd \n",
    "OLD_EPLUS_EXE = '/usr/local/EnergyPlus-8-8-0/energyplus'\n",
    "NEW_EPLUS_EXE = os.path.join(TRANSITION_CLI_DIR, 'energyplus-8.9.0')\n",
    "# NEW_EPLUS_EXE = '/home/julien/Software/Others/OS-build2/EnergyPlus-8.9.0-1c5ba897d1-Linux-x86_64/EnergyPlus-8-9-0/energyplus-8.9.0'\n",
    "\n",
    "# Path to OpenStudio CLIs\n",
    "# OLD_OS_CLI = '/usr/bin/openstudio-2.4.1'\n",
    "OLD_OS_CLI = '/home/julien/Software/Others/OS-build/Products/openstudio-2.4.2'\n",
    "NEW_OS_CLI = '/home/julien/Software/Others/OS-build2/Products/openstudio-2.4.3'\n",
    "\n",
    "# OLD_IDD_FILE = '/usr/local/EnergyPlus-8-8-0/Energy+.idd'\n",
    "# NEW_IDD_FILE = os.path.join(TRANSITION_DIR, 'Energy+.idd')\n",
    "\n",
    "# Put None if you want to run all tests\n",
    "REGRESSION_TEST_FILTER = '(kiva)|(baseline)'\n",
    "REGRESSION_TEST_FILTER = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the translation to work,\n",
    "# you'll have to chdir to the Transition CLI's folder\n",
    "TRANSITION_CLI = os.path.abspath(os.path.join(TRANSITION_CLI_DIR,\n",
    "                                             'Transition-V{}-to-V{}'.format(EPLUS_OLD_VERSION.replace('.', '-'),\n",
    "                                                                EPLUS_NEW_VERSION.replace('.', '-'))))\n",
    "TRANSITION_CLI"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import psutil\n",
    "physical_cpus = psutil.cpu_count(logical=False)\n",
    "multiprocessing.cpu_count() * (physical_cpus - 1) / physical_cpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of parallel processes\n",
    "if not N:\n",
    "    N = multiprocessing.cpu_count() - 2\n",
    "    print(\"Defaulting number of processes to {}\".format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories\n",
    "OLD_OS_DIR = \"{o}-{e}\".format(e=EPLUS_OLD_VERSION, o=OS_OLD_VERSION)\n",
    "OLD_OS_DIR = os.path.join(IDF_DIR, OLD_OS_DIR)\n",
    "\n",
    "NEW_OS_DIR = \"{o}-{e}\".format(e=EPLUS_NEW_VERSION, o=OS_NEW_VERSION)\n",
    "NEW_OS_DIR = os.path.join(IDF_DIR, NEW_OS_DIR)\n",
    "\n",
    "TRANSITION_DIR = \"Transition-{e}\".format(e=EPLUS_NEW_VERSION)\n",
    "TRANSITION_DIR = os.path.join(IDF_DIR, TRANSITION_DIR)\n",
    "\n",
    "for p in [OLD_OS_DIR, NEW_OS_DIR, TRANSITION_DIR]:\n",
    "    if not os.path.exists(p):\n",
    "        os.makedirs(p)\n",
    "        print('Creating directory: {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dicts to store all info\n",
    "OLD_OS_INFO = {'OS_VERSION': OS_OLD_VERSION,\n",
    "               'EPLUS_VERSION': EPLUS_OLD_VERSION,\n",
    "               'DIR': OLD_OS_DIR}\n",
    "\n",
    "NEW_OS_INFO = {'OS_VERSION': OS_NEW_VERSION,\n",
    "               'EPLUS_VERSION': EPLUS_NEW_VERSION,\n",
    "               'DIR': NEW_OS_DIR}\n",
    "\n",
    "TRANSITION_INFO = {'OS_VERSION': 'Transition',\n",
    "                   'EPLUS_VERSION': EPLUS_NEW_VERSION,\n",
    "                   'DIR': TRANSITION_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: Transition all regression tests and run them in both E+ versions\n",
    "\n",
    "TODO/Note: I guess I could just copy the SQL file from the OpenStudio-resources/model_tests.rb too..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in Previous OpenStudio Version based on old E+\n",
    "\n",
    "This will go in the `TESTRUNS_DIR ` (`OpenStudio-resources/testruns`) directory and find all IDF files and copy them to the `IDF_DIR` directory (typically the directory in which this notebook resides)\n",
    "\n",
    "<span style=\"font-size: 18px; color: red;\">It goes without saying: you need to have already run all simulation tests with the last OpenStudio version that is based on the old E+ version before running this section.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tests in the old version\n",
    "\n",
    "You can also just do that manually... but if you do, please delete the testruns/ folder beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all testruns to ensure we don't end up grabbing the idf and sql from another version\n",
    "if os.path.exists(TESTRUNS_DIR):\n",
    "    shutil.rmtree(TESTRUNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Pass 'CUSTOMTAG=' if you don't want a tag, or 'CUSTOMTAG=sha' for the build sha,\n",
    "# or any custom string such as 'CUSTOMTAG=Ubuntu_run1'\n",
    "CUSTOMTAG=''\n",
    "\n",
    "if REGRESSION_TEST_FILTER is None:\n",
    "    filt = ''\n",
    "else:\n",
    "    filt = \"-n /{}/\".format(REGRESSION_TEST_FILTER)\n",
    "\n",
    "command = \"env CUSTOMTAG={c} {cli} {m} {filt}\".format(c=CUSTOMTAG,\n",
    "                                                      m=os.path.join(OS_RES_DIR,\n",
    "                                                                     'model_tests.rb'),\n",
    "                                                      cli=OLD_OS_CLI,\n",
    "                                                      filt=filt)\n",
    "print(command)\n",
    "c_args = shlex.split(command)\n",
    "\n",
    "# Run it\n",
    "process = subprocess.Popen(c_args, shell=False,\n",
    "                           stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "# wait for the process to terminate\n",
    "#out, err = process.communicate()\n",
    "#errcode = process.returncode\n",
    "for line in iter(process.stdout.readline, b''):\n",
    "    l = line.rstrip().decode()\n",
    "    if 'extensions are not built' in l:\n",
    "        continue\n",
    "    print(l)\n",
    "process.stdout.close()\n",
    "process.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the Previous IDFs\n",
    "\n",
    "These end up directly in IDF_DIR. They will get copied to the `OLD_OS_DIR` during the Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup directory\n",
    "all_files = gb.glob(os.path.join(IDF_DIR, '*.idf'))\n",
    "all_files += gb.glob(os.path.join(IDF_DIR, '*.idfnew'))\n",
    "all_files += gb.glob(os.path.join(IDF_DIR, '*.idfold'))\n",
    "\n",
    "for f in all_files:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "found_idfs = []\n",
    "for f in gb.iglob(os.path.join(TESTRUNS_DIR, '**/*/in.idf')):\n",
    "    f2 = os.path.relpath(f, TESTRUNS_DIR)\n",
    "    \n",
    "    test_name = os.path.split(os.path.split(f2)[0])[0]\n",
    "    #print(test_name)\n",
    "    dst_path = os.path.join(IDF_DIR, \"{}.idf\".format(test_name))\n",
    "    shutil.copyfile(f, dst_path)\n",
    "    found_idfs.append(test_name)\n",
    "found_idfs = set(found_idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy all existing SQL files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_sqls = []\n",
    "\n",
    "for f in gb.iglob(os.path.join(TESTRUNS_DIR, '**/*/*.sql')):\n",
    "    f2 = os.path.relpath(f, TESTRUNS_DIR)\n",
    "    \n",
    "    test_name = os.path.split(os.path.split(f2)[0])[0]\n",
    "    # print(test_name)\n",
    "    dst_folder = os.path.join(OLD_OS_DIR, test_name)\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    dst_path = os.path.join(dst_folder, \"eplusout.sql\")\n",
    "    # print(dst_path)\n",
    "    shutil.copyfile(f, dst_path)\n",
    "    found_sqls.append(test_name)\n",
    "found_sqls = set(found_sqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_idfs), len(found_sqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_idfs - found_sqls"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rename directories and files\n",
    "for fn in os.listdir(NEW_DIR):\n",
    "    os.rename(fn, fn.replace('_8.9.0', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_file(path):\n",
    "    \"\"\"\n",
    "    Runs the file throught the transition utility and save in the right folder\n",
    "    Will move the ori file to the subdirectory OLD_DIR (eg `./8.8.0/`)\n",
    "    and the transitionned one to NEW_DIR (eg: `./8.9.0/`)\n",
    "    \"\"\"\n",
    "    \n",
    "    eplus_file, ext = os.path.splitext(os.path.split(path)[1])\n",
    "    \n",
    "    process = subprocess.Popen([TRANSITION_CLI, path],\n",
    "                               shell=False,\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE)\n",
    "    # wait for the process to terminate\n",
    "    out, err = process.communicate()\n",
    "    errcode = process.returncode\n",
    "    if errcode == 0:        \n",
    "        # Move the resulting IDF into the new dir\n",
    "        new_file = os.path.join(IDF_DIR, \"{f}.idfnew\".format(f=eplus_file))\n",
    "        new_dest = os.path.join(TRANSITION_DIR, \"{f}.idf\".format(f=eplus_file))\n",
    "        shutil.move(new_file, new_dest)\n",
    "        \n",
    "        # Move the old version into its directory\n",
    "        old_file = os.path.join(IDF_DIR, \"{f}.idfold\".format(f=eplus_file))\n",
    "        old_dest = os.path.join(OLD_OS_DIR, \"{f}.idf\".format(f=eplus_file))\n",
    "        shutil.move(old_file, old_dest)\n",
    "        \n",
    "        # Delete original file\n",
    "        ori_file = os.path.join(IDF_DIR, \"{f}.idf\".format(f=eplus_file))\n",
    "        os.remove(ori_file)\n",
    "        \n",
    "        # print('Done for {}.idf - {}'.format(eplus_file, path))\n",
    "    else:\n",
    "        print(\"Error for {}\".format(path))\n",
    "        print(out)\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.abspath(file) for file in gb.glob(os.path.join(IDF_DIR, '*.idf'))]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSITION_CLI_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must cd to the Transition CLI's folder for it to work\n",
    "os.chdir(TRANSITION_CLI_DIR)\n",
    "\n",
    "# Takes about 10minutes on my machine with 12 threads allocated\n",
    "pool = multiprocessing.Pool(processes=N)\n",
    "\n",
    "desc = '<h3>Translation from {} to {}</h3>'.format(EPLUS_OLD_VERSION,\n",
    "                                                   EPLUS_NEW_VERSION)\n",
    "label = HTML(desc)\n",
    "display(label)\n",
    "for _ in tqdm.tqdm_notebook(pool.imap_unordered(translate_file, files), total=len(files)):\n",
    "    pass\n",
    "\n",
    "os.chdir(IDF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, you shouldn't have any .idf files in the IDF_DIR directory\n",
    "# If you do, means that the transition failed\n",
    "all_files = gb.glob(os.path.join(IDF_DIR, '*.idf'))\n",
    "all_files += gb.glob(os.path.join(IDF_DIR, '*.idfnew'))\n",
    "all_files += gb.glob(os.path.join(IDF_DIR, '*.idfold'))\n",
    "\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation in E+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GJ_TO_KBTU= 947.8171203133173\n",
    "\n",
    "SQL_QUERY_TOTAL_SITE_KBTU = \"SELECT Value FROM tabulardatawithstrings WHERE \\\n",
    "                              ReportName='AnnualBuildingUtilityPerformanceSummary' AND \\\n",
    "                              ReportForString='Entire Facility' AND \\\n",
    "                              TableName='Site and Source Energy' AND \\\n",
    "                              RowName='Total Site Energy' AND \\\n",
    "                              ColumnName='Total Energy' AND \\\n",
    "                              Units='GJ'\"\n",
    "\n",
    "SQL_QUERY_SIM_INFO = 'SELECT EnergyPlusVersion FROM Simulations'\n",
    "\n",
    "VERSION_REGEX = re.compile(r'Version (?P<Major>\\d+)\\.(?P<Minor>\\d+)\\.'\n",
    "                                   '(?P<Patch>\\d+)-(?P<SHA>\\w+),\\s+'\n",
    "                                   'YMD=(?P<datestring>[0-9\\.: ]+)')\n",
    "\n",
    "\n",
    "# Remove all files in the output directory except these\n",
    "KEEP_EXT = ['.err', '.sql']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sql_version_and_sitekbtu(output_directory):\n",
    "    \"\"\"\n",
    "    This function grabs the EnergyPlusVersion and the total site energy\n",
    "    from the SQL file.\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    * output_directory (str): the path were the SQL should be.\n",
    "        eg: `./8.8.0/absorption_chillers.osm_8.8.0/`\n",
    "    \n",
    "    Returns:\n",
    "    ---------\n",
    "    * pd.Series that has the version with SHA and site kbtu\n",
    "        (or None if it didn't run), which name is the test_name\n",
    "        (gotten from the name of the output_directory)\n",
    "    \"\"\"\n",
    "    sql_files = gb.glob(os.path.join(output_directory, \"*.sql\"))\n",
    "\n",
    "    version_with_sha = None\n",
    "    site_kbtu = None\n",
    "\n",
    "    if len(sql_files) == 1:\n",
    "        sql_path = sql_files[0]\n",
    "        abs_sql_path = os.path.abspath(sql_path)\n",
    "        sql_uri = '{}?mode=ro'.format(pathlib.Path(abs_sql_path).as_uri())\n",
    "        with sqlite3.connect(sql_uri, uri=True) as con:\n",
    "                cursor = con.cursor()\n",
    "                r = cursor.execute(SQL_QUERY_SIM_INFO).fetchone()\n",
    "                if r:\n",
    "                    simulation_info = r[0]\n",
    "                    m = VERSION_REGEX.search(simulation_info)\n",
    "                    if m:\n",
    "                        gpdict = m.groupdict()\n",
    "                        version_with_sha = \"{}.{}.{}-{}\".format(gpdict['Major'],\n",
    "                                                                     gpdict['Minor'],\n",
    "                                                                     gpdict['Patch'],\n",
    "                                                                     gpdict['SHA'])\n",
    "                else:\n",
    "                    msg = (\"Cannot find the EnergyPlusVersion in the SQL file. \"\n",
    "                           \"For:\\n{}\".format(output_directory))\n",
    "                    #raise ValueError(msg)\n",
    "                    print(msg)\n",
    "\n",
    "                # Get Site kBTU\n",
    "                r = cursor.execute(SQL_QUERY_TOTAL_SITE_KBTU).fetchone()\n",
    "                if r:\n",
    "                    site_gj = float(r[0])\n",
    "                    site_kbtu = site_gj * GJ_TO_KBTU\n",
    "                    msg = (\"Cannot find the Total Site Energy in the SQL file. \"\n",
    "                           \"For:\\n{}\".format(output_directory))\n",
    "    return pd.Series([version_with_sha, site_kbtu],\n",
    "                     index=['E+', 'SiteKBTU'],\n",
    "                     name = os.path.split(output_directory)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_OLD_eplus_sim(eplus_file):\n",
    "    \"\"\"\n",
    "    Runs the simulation with OLD_EPLUS_EXE and calls parse_sql\n",
    "    \"\"\"\n",
    "    base, file_with_ext = os.path.split(os.path.abspath(eplus_file))\n",
    "    output_directory = os.path.join(base, os.path.splitext(file_with_ext)[0])\n",
    "    # If directory exists, delete it\n",
    "    if os.path.exists(output_directory):\n",
    "        shutil.rmtree(output_directory)\n",
    "    # Recreate it\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "    process = subprocess.Popen([OLD_EPLUS_EXE,\n",
    "                                # '-i', OLD_IDD_FILE\n",
    "                                '-w', WEATHER_FILE,\n",
    "                                '-d', output_directory,\n",
    "                               eplus_file],\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               universal_newlines=True, \n",
    "                               shell=False)\n",
    "    \n",
    "    # wait for the process to terminate\n",
    "    out, err = process.communicate()\n",
    "    errcode = process.returncode\n",
    "    if errcode == 0:\n",
    "        # Clean up output directory\n",
    "        [os.remove(x) for x in gb.glob(os.path.join(output_directory, '*'))\n",
    "         if os.path.splitext(x)[1] not in KEEP_EXT]\n",
    "        return parse_sql_version_and_sitekbtu(output_directory)\n",
    "    else:\n",
    "        print(\"ERROR: {}\".format(eplus_file))\n",
    "        print(out)\n",
    "        print(err)\n",
    "        return pd.Series([None, None],\n",
    "                     index=['E+', 'SiteKBTU'],\n",
    "                     name = os.path.split(output_directory)[1])\n",
    "    \n",
    "def run_NEW_eplus_sim(eplus_file):\n",
    "    \"\"\"\n",
    "    Runs the simulation with NEW_EPLUS_EXE and calls parse_sql\n",
    "    \"\"\"\n",
    "    base, file_with_ext = os.path.split(os.path.abspath(eplus_file))\n",
    "    output_directory = os.path.join(base, os.path.splitext(file_with_ext)[0])\n",
    "    # If directory exists, delete it\n",
    "    if os.path.exists(output_directory):\n",
    "        shutil.rmtree(output_directory)\n",
    "    # Recreate it\n",
    "    os.makedirs(output_directory)\n",
    "    \n",
    "    process = subprocess.Popen([NEW_EPLUS_EXE,\n",
    "                                # '-i', OLD_IDD_FILE\n",
    "                                '-w', WEATHER_FILE,\n",
    "                                '-d', output_directory,\n",
    "                               eplus_file],\n",
    "                               stdout=subprocess.PIPE,\n",
    "                               stderr=subprocess.PIPE,\n",
    "                               universal_newlines=True, \n",
    "                               shell=False)\n",
    "    \n",
    "    # wait for the process to terminate\n",
    "    out, err = process.communicate()\n",
    "    errcode = process.returncode\n",
    "    if errcode == 0:\n",
    "        # Clean up output directory\n",
    "        [os.remove(x) for x in gb.glob(os.path.join(output_directory, '*'))\n",
    "         if os.path.splitext(x)[1] not in KEEP_EXT]\n",
    "        return parse_sql_version_and_sitekbtu(output_directory)\n",
    "    else:\n",
    "        print(\"ERROR: {}\".format(eplus_file))\n",
    "        # print(out)\n",
    "        # print(err)\n",
    "        return pd.Series([None, None],\n",
    "                     index=['E+', 'SiteKBTU'],\n",
    "                     name = os.path.split(output_directory)[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test one sim\n",
    "files = gb.glob(os.path.join(NEW_DIR, '*.idf'))\n",
    "eplus_file = files[0]\n",
    "run_NEW_eplus_sim(eplus_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all 8.8.0 files or just load SQL\n",
    "\n",
    "#### Rerun in old E+\n",
    "\n",
    "This should take about 10-15 minutes depending on your machine.\n",
    "\n",
    "It is currently disabled (as RawNBConvert) because we should have already copied the needed SQL files from the old OpenStudio version that is based on the old EnergyPlus Version. Switch this cell to \"Code\" if you do want to rerun with your old installed E+ version"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "files = gb.glob(os.path.join(OLD_DIR, '*.idf'))\n",
    "\n",
    "pool = multiprocessing.Pool(processes=N)\n",
    "\n",
    "desc = '<h3>Running files for version {}</h3>'.format(OLD_VERSION)\n",
    "label = HTML(desc)\n",
    "display(label)\n",
    "all_results = []\n",
    "for result in tqdm.tqdm_notebook(pool.imap_unordered(run_OLD_eplus_sim, files), total=len(files)):\n",
    "    all_results.append(result)\n",
    "   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Concat in dataframe and save to CSV\n",
    "old_results = pd.concat(all_results, axis=1).T\n",
    "old_results.to_csv(os.path.join(IDF_DIR, 'kbtus_8.8.0.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just parse copied SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results = pd.concat([parse_sql_version_and_sitekbtu(os.path.join(OLD_OS_DIR, x)) \n",
    "                         for x in os.listdir(OLD_OS_DIR)\n",
    "                         if os.path.isdir(os.path.join(OLD_OS_DIR, x))],\n",
    "                        axis=1).T\n",
    "\n",
    "old_results['OS'] = OS_OLD_VERSION\n",
    "\n",
    "old_results.to_csv(os.path.join(IDF_DIR, 'kbtus_{o}-{e}.csv'.format(e=EPLUS_OLD_VERSION,\n",
    "                                                                    o=OS_OLD_VERSION)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all 8.9.0 files\n",
    "\n",
    "This should take about 10-15 minutes depending on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = gb.glob(os.path.join(TRANSITION_DIR, '*.idf'))\n",
    "files[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# About 15-20minutes with 12 threads for all tests\n",
    "files = gb.glob(os.path.join(TRANSITION_DIR, '*.idf'))\n",
    "\n",
    "pool = multiprocessing.Pool(processes=N)\n",
    "\n",
    "desc = '<h3>Running Transitioned files in E+ {}</h3>'.format(EPLUS_NEW_VERSION)\n",
    "label = HTML(desc)\n",
    "display(label)\n",
    "all_results = []\n",
    "for result in tqdm.tqdm_notebook(pool.imap_unordered(run_NEW_eplus_sim, files), total=len(files)):\n",
    "    all_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat in dataframe and save to CSV\n",
    "transitioned_results = pd.concat(all_results, axis=1).T\n",
    "transitioned_results['OS'] = 'Transition'\n",
    "transitioned_results.to_csv(os.path.join(IDF_DIR, 'kbtus_Transition-{e}.csv'.format(e=EPLUS_NEW_VERSION)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitioned_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_results.index), len(transitioned_results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "set(old_results.index) - set(transitioned_results.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulation in new OpenStudio based on new EnergyPlus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run New OS Version regression tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all testruns to ensure we don't end up grabbing the idf and sql from another version\n",
    "# model_tests.rb only cleans out testruns/testXXX directories for tests we do request\n",
    "# So if you use a regression test filter, you could have left overs\n",
    "if os.path.exists(TESTRUNS_DIR):\n",
    "    shutil.rmtree(TESTRUNS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass 'CUSTOMTAG=' if you don't want a tag, or 'CUSTOMTAG=sha' for the build sha,\n",
    "# or any custom string such as 'CUSTOMTAG=Ubuntu_run1'\n",
    "CUSTOMTAG=''\n",
    "\n",
    "if REGRESSION_TEST_FILTER is None:\n",
    "    filt = ''\n",
    "else:\n",
    "    filt = \"-n /{}/\".format(REGRESSION_TEST_FILTER)\n",
    "\n",
    "command = \"env CUSTOMTAG={c} {cli} {m} {filt}\".format(c=CUSTOMTAG,\n",
    "                                                      m=os.path.join(OS_RES_DIR,\n",
    "                                                                     'model_tests.rb'),\n",
    "                                                      cli=NEW_OS_CLI,\n",
    "                                                      filt=filt)\n",
    "print(command)\n",
    "c_args = shlex.split(command)\n",
    "c_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.Popen(c_args, shell=False,\n",
    "                           stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "# wait for the process to terminate\n",
    "#out, err = process.communicate()\n",
    "#errcode = process.returncode\n",
    "lines = []\n",
    "for line in iter(process.stdout.readline, b''):\n",
    "    print(line.rstrip().decode())\n",
    "    lines.append(line)\n",
    "process.stdout.close()\n",
    "process.wait()\n",
    "    \n",
    "#os.chdir(IDF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy IDF\n",
    "\n",
    "Copy to the `NEW_OS_DIR` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_idfs = []\n",
    "for f in gb.iglob(os.path.join(TESTRUNS_DIR, '**/*/in.idf')):\n",
    "    f2 = os.path.relpath(f, TESTRUNS_DIR)\n",
    "    \n",
    "    test_name = os.path.split(os.path.split(f2)[0])[0]\n",
    "    #print(test_name)\n",
    "    dst_path = os.path.join(NEW_OS_DIR, \"{}.idf\".format(test_name))\n",
    "    shutil.copyfile(f, dst_path)\n",
    "    found_idfs.append(test_name)\n",
    "found_idfs = set(found_idfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_sqls = []\n",
    "\n",
    "for f in gb.iglob(os.path.join(TESTRUNS_DIR, '**/*/*.sql')):\n",
    "    f2 = os.path.relpath(f, TESTRUNS_DIR)\n",
    "    \n",
    "    test_name = os.path.split(os.path.split(f2)[0])[0]\n",
    "    # print(test_name)\n",
    "    dst_folder = os.path.join(NEW_OS_DIR, test_name)\n",
    "    if not os.path.exists(dst_folder):\n",
    "        os.makedirs(dst_folder)\n",
    "    dst_path = os.path.join(dst_folder, \"eplusout.sql\")\n",
    "    # print(dst_path)\n",
    "    shutil.copyfile(f, dst_path)\n",
    "    found_sqls.append(test_name)\n",
    "found_sqls = set(found_sqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(found_idfs), len(found_sqls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "found_idfs - found_sqls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse new SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results = pd.concat([parse_sql_version_and_sitekbtu(os.path.join(NEW_OS_DIR, x)) \n",
    "                         for x in os.listdir(NEW_OS_DIR)\n",
    "                         if os.path.isdir(os.path.join(NEW_OS_DIR, x))],\n",
    "                        axis=1).T\n",
    "\n",
    "new_results['OS'] = OS_NEW_VERSION\n",
    "\n",
    "new_results.to_csv(os.path.join(IDF_DIR, 'kbtus_{o}-{e}.csv'.format(e=EPLUS_NEW_VERSION,\n",
    "                                                                    o=OS_NEW_VERSION)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2: Analyzing differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparse SQLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we could just reparse the SQLs...\n",
    "\n",
    "old_results = pd.concat([parse_sql_version_and_sitekbtu(os.path.join(OLD_OS_DIR, x)) \n",
    "                         for x in next(os.walk(OLD_OS_DIR))[1]],\n",
    "                        axis=1).T\n",
    "old_results['OS'] = OS_OLD_VERSION\n",
    "\n",
    "\n",
    "transitioned_results = pd.concat([parse_sql_version_and_sitekbtu(os.path.join(TRANSITION_DIR, x)) \n",
    "                        for x in next(os.walk(TRANSITION_DIR))[1]],\n",
    "                        axis=1).T\n",
    "transitioned_results['OS'] = 'Transition'\n",
    "\n",
    "\n",
    "new_results = pd.concat([parse_sql_version_and_sitekbtu(os.path.join(NEW_OS_DIR, x)) \n",
    "                         for x in next(os.walk(NEW_OS_DIR))[1]],\n",
    "                        axis=1).T\n",
    "new_results['OS'] = OS_NEW_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(old_results.index), len(transitioned_results.index), len(new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(old_results.index) - set(transitioned_results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(old_results.index) - set(new_results.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_results.to_csv(os.path.join(IDF_DIR,\n",
    "                                'kbtus_{o}-{e}.csv'.format(e=EPLUS_OLD_VERSION,\n",
    "                                                           o=OS_OLD_VERSION)))\n",
    "\n",
    "transitioned_results.to_csv(os.path.join(IDF_DIR,\n",
    "                                         'kbtus_Transition-{e}.csv'.format(e=EPLUS_NEW_VERSION)))\n",
    "\n",
    "new_results.to_csv(os.path.join(IDF_DIR,\n",
    "                                'kbtus_{o}-{e}.csv'.format(e=EPLUS_NEW_VERSION,\n",
    "                                                           o=OS_NEW_VERSION)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload site kbtu csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(IDF_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "old_results = pd.read_csv(os.path.join(IDF_DIR, 'kbtus_{o}-{e}.csv'.format(e=EPLUS_OLD_VERSION,\n",
    "                                                                    o=OS_OLD_VERSION)), index_col=0)\n",
    "\n",
    "transitioned_results = pd.read_csv(os.path.join(IDF_DIR, \n",
    "                                                'kbtus_Transition-{e}.csv'.format(e=EPLUS_NEW_VERSION)),\n",
    "                                                index_col=0)\n",
    "\n",
    "new_results = pd.read_csv(os.path.join(IDF_DIR, 'kbtus_{o}-{e}.csv'.format(e=EPLUS_NEW_VERSION,\n",
    "                                                                    o=OS_NEW_VERSION)), index_col=0)\n",
    "\n",
    "# Strip the version from the index (shouldn't be needed anymore)\n",
    "#old_results.index = [x.replace('_{}'.format(OLD_VERSION),'') for x in old_results.index]\n",
    "#new_results.index = [x.replace('_{}'.format(NEW_VERSION),'') for x in new_results.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([old_results.dropna(how='all'),\n",
    "                transitioned_results.dropna(how='all'),\n",
    "                new_results.dropna(how='all')])\n",
    "\n",
    "df = df.set_index(['E+', 'OS'], append=True).unstack([1,2])['SiteKBTU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problems\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throwing out these problems for further analysis (they need to be investigated on the site)\n",
    "df = df.dropna(how='any', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at where we have deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "pct_threshold = 0.0001\n",
    "print(\"Setting % diff threshold to {:.3%}\".format(pct_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviations in Transition and/or new OpenStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_diff = df.pct_change(axis=1).iloc[:, 1:].dropna()\n",
    "df_diff = df_diff[(df_diff >= pct_threshold).any(axis=1)]\n",
    "#df_diff = df_diff.sort_values(by=df_diff.columns[-1],\n",
    "#                              ascending=True)\n",
    "# Sort by max absolute diff\n",
    "df_diff = df_diff.loc[df_diff.abs().max(axis=1).sort_values(ascending=True).index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, sharex=True, sharey=True,\n",
    "                               figsize=(16, len(df_diff)/2))\n",
    "df_diff.iloc[:,0].plot(kind='barh', ax=ax0)\n",
    "df_diff.iloc[:,1].plot(kind='barh', ax=ax1)\n",
    "\n",
    "vals = ax0.get_xticks()\n",
    "ax0.set_xticklabels(['{:3.2f}%'.format(x*100) for x in vals])\n",
    "\n",
    "ax0.set_title(\"% difference between {}\\nand {}\".format(df.columns[0], df.columns[1]))\n",
    "ax0.set_xlabel(\"% difference\")\n",
    "\n",
    "ax1.set_title(\"% difference between {}\\nand {}\".format(df.columns[1], df.columns[2]))\n",
    "ax1.set_xlabel(\"% difference\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviations from Transition to new OS only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_os_diff = df_diff[df_diff.iloc[:,-1] != 0]\n",
    "new_os_diff.style.format('{:.5%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(ncols=2, nrows=1, sharex=True, sharey=True,\n",
    "                               figsize=(16, len(new_os_diff)/2))\n",
    "new_os_diff.iloc[:,0].plot(kind='barh', ax=ax0)\n",
    "new_os_diff.iloc[:,1].plot(kind='barh', ax=ax1)\n",
    "\n",
    "vals = ax0.get_xticks()\n",
    "ax0.set_xticklabels(['{:3.2f}%'.format(x*100) for x in vals])\n",
    "\n",
    "ax0.set_title(\"% difference between {}\\nand {}\".format(df.columns[0], df.columns[1]))\n",
    "ax0.set_xlabel(\"% difference\")\n",
    "\n",
    "ax1.set_title(\"% difference between {}\\nand {}\".format(df.columns[1], df.columns[2]))\n",
    "ax1.set_xlabel(\"% difference\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped bar chart of differences compared to the old OpenStudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to read this chart**:\n",
    "\n",
    "The percentage differences are calculated compared to the Old OpenStudio results for both the transitioned results and the new OpenStudio results.\n",
    "\n",
    "**What you need to pay special attention to is when you don't have the same difference between the Transition to Old OS and the New OS to old OS** (meaning the difference is not E+'s fault, but OpenStudio's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.columns = df2.columns.droplevel(0)\n",
    "\n",
    "df_diff_from_old_os = df2.iloc[:,1:].subtract(df2.iloc[:,0], axis=0).divide(df2.iloc[:,0], axis=0)\n",
    "\n",
    "# Keep only over threshold\n",
    "df_diff_from_old_os = df_diff_from_old_os[(df_diff_from_old_os >= pct_threshold).any(axis=1)]\n",
    "\n",
    "# Sort by max absolute diff\n",
    "df_diff_from_old_os = df_diff_from_old_os.loc[df_diff_from_old_os.abs().max(axis=1).sort_values(ascending=True).index]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, len(df_diff_from_old_os)/2))\n",
    "df_diff_from_old_os.plot(kind='barh', stacked=False, ax=ax)\n",
    "\n",
    "vals = ax.get_xticks()\n",
    "ax.set_xticklabels(['{:3.2f}%'.format(x*100) for x in vals])\n",
    "\n",
    "ax.set_title(\"% difference compared to  {}\".format(df.columns[0]))\n",
    "ax.set_xlabel(\"% difference\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Sort the other way round for the table\n",
    "(df_diff_from_old_os\n",
    "    .loc[df_diff_from_old_os.abs().max(axis=1)\n",
    "                            .sort_values(ascending=False).index]\n",
    "    .style.format('{:.2%}'))\n",
    "\n",
    "#html = df_diff_from_old_os.style.format('{:.2%}').render()\n",
    "#display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked bar chart of differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ymax_bylabel(label, ax, y_is_top=False):\n",
    "    \"\"\"\n",
    "    Given a label, find the y for that bar, and the max x based on two stacked\n",
    "    bars\n",
    "    \"\"\"\n",
    "    for i, x in enumerate(ax.get_yticklabels()):\n",
    "        if x.get_text() == label:\n",
    "            # y = x.get_position()[1]\n",
    "            \n",
    "            # Find the max x between the two rects\n",
    "            rect1 =  ax.patches[i]\n",
    "            rect_1_xmax = rect1.get_x() + rect1.get_width()\n",
    "            \n",
    "            if y_is_top:\n",
    "                y = rect1.get_y() + rect1.get_height()\n",
    "            else:\n",
    "                y = rect1.get_y() + rect1.get_height() / 2.0\n",
    "                y = x.get_position()[1]\n",
    "            \n",
    "            rect2 = ax.patches[int(i+(len(ax.patches) / 2))]\n",
    "            rect_2_xmax = rect2.get_x() + rect2.get_width()\n",
    "            \n",
    "            return y, max(rect_1_xmax, rect_2_xmax)\n",
    "    return None, None\n",
    "\n",
    "def plot_stacked_bar_difference_compared_to_base(toplot):\n",
    "    fig, ax = plt.subplots(figsize=(16, len(toplot)/2))\n",
    "\n",
    "    # Total % change from old os to new os\n",
    "    s_tot_change = toplot.sum(axis=1)\n",
    "\n",
    "    toplot.plot(kind='barh', stacked=True, ax=ax)\n",
    "\n",
    "    vals = ax.get_xticks()\n",
    "    ax.set_xticklabels(['{:3.2f}%'.format(x*100) for x in vals])\n",
    "\n",
    "    ax.set_title(\"% difference compared to  {}\".format(df.columns[0]))\n",
    "    ax.set_xlabel(\"% difference\")\n",
    "\n",
    "    # for i, rect in enumerate(ax.patches):\n",
    "    #     label = ax.get_yticklabels()[int(i % (len(ax.patches) / 2))].get_text()\n",
    "    #     tot_change = s_tot_change[label]\n",
    "    #     ax.annotate(\"{}-{}-{:.3%}\".format(i, label, tot_change), \n",
    "    #                 xy=(rect.get_x()+rect.get_width(), rect.get_y()))\n",
    "\n",
    "    # Need to draw first otherwise we can't get the position\n",
    "    ax.figure.canvas.draw()\n",
    "\n",
    "\n",
    "\n",
    "    # Add TOTAL % change (sum of both)           \n",
    "    for label, val in s_tot_change.items():\n",
    "        ymid, xmax = find_ymax_bylabel(label=label, ax=ax, y_is_top=False)\n",
    "        ytop, xmax = find_ymax_bylabel(label=label, ax=ax, y_is_top=True)\n",
    "        if xmax is not None:\n",
    "            ax.annotate(\"{:.3%}\".format(val),\n",
    "                        xy=(val, ytop), xycoords='data',\n",
    "                        ha='center', va='bottom', color='k', fontsize=8,\n",
    "                        xytext=(0, 4), textcoords='offset points') \n",
    "            ax.plot(val, ytop, marker='v', c='#494949', alpha=1, zorder=3)\n",
    "\n",
    "    # Custom annotations\n",
    "    label = 'baseline_sys07.rb'\n",
    "    y, xmax = find_ymax_bylabel(label=label, ax=ax, y_is_top=False)\n",
    "    if y is not None:\n",
    "        ax.annotate(\"Slight OpenStudio deviation here\", xy=(xmax, y), xycoords='data',\n",
    "                    ha='left', va='center',\n",
    "                    xytext=(20, 0), textcoords='offset points',\n",
    "                    arrowprops=dict(arrowstyle=\"->\",\n",
    "                                connectionstyle=\"arc3\"))\n",
    "\n",
    "    label = 'centralheatpumpsystem.rb'\n",
    "    y, xmax = find_ymax_bylabel(label=label, ax=ax, y_is_top=False)\n",
    "    if y is not None:\n",
    "        ax.annotate(\"This ruby test is unstable, period\", xy=(xmax, y), xycoords='data',\n",
    "                    ha='left', va='center',\n",
    "                    xytext=(20, 0), textcoords='offset points',\n",
    "                    arrowprops=dict(arrowstyle=\"->\",\n",
    "                                connectionstyle=\"arc3\")) \n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to read this chart**:\n",
    "\n",
    "The percentage differences are calculated compared to the Old OpenStudio results for both the transitioned results and the new OpenStudio results. Then I do\n",
    "\n",
    "    % diff New version = % diff New version - % diff Transition\n",
    "\n",
    "and plot that as a stacked bar chart.\n",
    "The goal is to more clearly see the differences that are due to OpenStudio by removing the differences due to the new E+.\n",
    "\n",
    "**What you need to pay special attention to is when you see % differences for the new OS.**\n",
    "\n",
    "**A cursor along with the total % difference between Old OS and New OS is also plotted**.\n",
    "Please see the below example to get a better sense of how the graph is constructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_from_old_example = pd.DataFrame([[0.003, 0.0005],\n",
    "                                         [-0.0004, +0.0003],\n",
    "                                         [0.0002, 0.0004]],\n",
    "                                        index=['test1.rb', 'test2.osm', 'test3.rb'],\n",
    "                                        columns=['Transition', '2.4.3']\n",
    "                                       )\n",
    "plot_stacked_bar_difference_compared_to_base(df_diff_from_old_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's do the actual plotting now:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_from_old_os_as_pct = df_diff_from_old_os.copy()\n",
    "df_diff_from_old_os_as_pct.loc[:,OS_NEW_VERSION] = df_diff_from_old_os_as_pct.loc[:,OS_NEW_VERSION] - df_diff_from_old_os_as_pct.loc[:,'Transition']\n",
    "\n",
    "plot_stacked_bar_difference_compared_to_base(df_diff_from_old_os_as_pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect biggest differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_annual_energy_by_fuel_and_enduse(sql_path):\n",
    "    \"\"\"\n",
    "    Queries SQL file and returns the ABUPS' End Uses table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sql_path (str): path to the sql file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_annual: pd.DataFrame\n",
    "        Annual End Use table\n",
    "        index = 'EndUse'\n",
    "        columns = ['FuelType','Units']\n",
    "    \"\"\"\n",
    "\n",
    "    abs_sql_path = os.path.abspath(sql_path)\n",
    "    sql_uri = '{}?mode=ro'.format(pathlib.Path(abs_sql_path).as_uri())\n",
    "    \n",
    "    # RowName = '#{end_use}'\n",
    "    # ColumnName='#{fuel_type}'\n",
    "    annual_end_use_query = \"\"\"SELECT RowName, ColumnName, Units, Value\n",
    "        FROM TabularDataWithStrings\n",
    "        WHERE ReportName='AnnualBuildingUtilityPerformanceSummary'\n",
    "        AND ReportForString='Entire Facility'\n",
    "        AND TableName='End Uses'\n",
    "    \"\"\"\n",
    "\n",
    "    with sqlite3.connect(sql_uri, uri=True) as con:\n",
    "        df_annual = pd.read_sql(annual_end_use_query, con=con)\n",
    "\n",
    "    # Convert Value to Float\n",
    "    df_annual['Value'] = pd.to_numeric(df_annual['Value'])\n",
    "\n",
    "    df_annual = df_annual.set_index(['RowName',\n",
    "                                     'ColumnName',\n",
    "                                     'Units'])['Value'].unstack([1, 2])\n",
    "    df_annual.index.name = 'EndUse'\n",
    "    df_annual.columns.names = ['FuelType', 'Units']\n",
    "\n",
    "    end_use_order = ['Heating', 'Cooling',\n",
    "                     'Interior Lighting', 'Exterior Lighting',\n",
    "                     'Interior Equipment', 'Exterior Equipment',\n",
    "                     'Fans', 'Pumps', 'Heat Rejection', 'Humidification',\n",
    "                     'Heat Recovery', 'Water Systems',\n",
    "                     'Refrigeration', 'Generators']\n",
    "\n",
    "    col_order = ['Electricity', 'Natural Gas', 'Additional Fuel',\n",
    "                 'District Cooling', 'District Heating', 'Water']\n",
    "\n",
    "    df_annual = df_annual[col_order].loc[end_use_order]\n",
    "\n",
    "    return df_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sql_file(test, version_info):\n",
    "    \"\"\"\n",
    "    Find the sql file given a test name and the version_info dict\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * test (str): the test name\n",
    "    * version_info (dict): should have at least one 'DIR' key with the path\n",
    "    to the directory\n",
    "    \"\"\"\n",
    "    search_path = os.path.join(version_info['DIR'], test, \"*.sql\")\n",
    "\n",
    "    sql_files = gb.glob(search_path)\n",
    "\n",
    "    if len(sql_files) == 0:\n",
    "        return None\n",
    "    elif len(sql_files) > 1:\n",
    "        print(\"Found more than one sql file for {t} in \"\n",
    "              \"{p}\".format(t=test, p=search_path))\n",
    "    return sql_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_single_end_use(test, version_info):\n",
    "    \"\"\"\n",
    "    Helper to load the end use by fuel\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * test (str): the test name\n",
    "    * version_info (dict): should have at least one 'DIR' key with the path\n",
    "    to the directory\n",
    "    \"\"\"\n",
    "    sql_path = find_sql_file(test, version_info=version_info)\n",
    "    if sql_path is None:\n",
    "        print(\"Cannot find the sql file for test '{}' and version \"\n",
    "              \"{}\".format(test, version_info['OS_VERSION']))\n",
    "        return None\n",
    "\n",
    "    end_use = get_annual_energy_by_fuel_and_enduse(sql_path)\n",
    "    end_use.columns = pd.MultiIndex.from_tuples([(version_info['OS_VERSION'],) + x for x in end_use.columns],\n",
    "                                                names = ['Version'] + end_use.columns.names)\n",
    "    return end_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def parse_before_after_enduse(test, old_os=True, transition=True, new_os=True):\n",
    "    \"\"\"\n",
    "    Given a test name, will parse both the old and the new SQL file to return\n",
    "    a table that has, for both versions, the end use by fuel values\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * test (str): the name of the test. eg 'foundation_kiva.osm'\n",
    "    * old_os, transition, new_os (bool): whether to include these versions\n",
    "    Note that it relies on the respective global dictionaries\n",
    "    OLD_OS_INFO, TRANSITION_INFO, NEW_OS_INFO\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    * df_all_end_use (pd.DataFrame): a multiindex dataframe of end uses by fuel\n",
    "        index: ['EndUse'] ('Heating', 'Cooling', etc)\n",
    "        columns = ['Version', 'FuelType', 'Units']\n",
    "\n",
    "    \"\"\"\n",
    "    concat_list = []\n",
    "    \n",
    "    if (old_os + transition + new_os) < 2:\n",
    "        print(\"You should request at least 2 versions to compare them...\")\n",
    "        return False\n",
    "    \n",
    "    if old_os:\n",
    "        concat_list.append(parse_single_end_use(test, OLD_OS_INFO))\n",
    "    if transition:\n",
    "        concat_list.append(parse_single_end_use(test, TRANSITION_INFO))\n",
    "    if new_os:\n",
    "        concat_list.append(parse_single_end_use(test, NEW_OS_INFO))\n",
    "\n",
    "        \n",
    "    df_all_end_use = pd.concat([x for x in concat_list if x is not None],\n",
    "                               axis=1)\n",
    "\n",
    "    return df_all_end_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_end_use_diff(df_all_end_use, test,\n",
    "                      add_legend=True, fontsize=None,\n",
    "                      outer_i=None, fig=None):\n",
    "    \"\"\"\n",
    "    Plots the difference in end use by fuel between the new and old versions\n",
    "    Will have subplots by units (water versus energy), a subplot is only shown\n",
    "    if there is consumption in the said end use (eg if no Water, there will \n",
    "    be only one subplot)\n",
    "    Displays a grouped bar chart by end use, and annotates % difference in the\n",
    "    given end use\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * both_end_use (pd.DataFrame): dataframe from `parse_before_after_enduse`\n",
    "    \n",
    "    * outer_i and fig: if you want to customize the layout yourself. \n",
    "        Pass None otherwise (default)\n",
    "        \n",
    "    * old_info, new_info (dict): dict with information such as 'DIR', \n",
    "    'EPLUS_VERSION' and 'OS_VERSION'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    * None, displays a plot\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if fontsize is None:\n",
    "        fontsize = 10\n",
    "    \n",
    "    diff = (df_all_end_use.groupby(level=['Version', 'Units'], axis=1).sum()\n",
    "                          .replace(0, np.nan)\n",
    "                          .dropna(how='all', axis=0)\n",
    "                          .dropna(how='all', axis=1))\n",
    "\n",
    "    # Reorder properly\n",
    "    diff = diff[[x for x in [OLD_OS_INFO['OS_VERSION'],\n",
    "                 TRANSITION_INFO['OS_VERSION'],\n",
    "                 NEW_OS_INFO['OS_VERSION']] if x in diff.columns]]\n",
    "    \n",
    "    grouped = diff.groupby(level='Units', axis=1)\n",
    "\n",
    "    ncols = min(len(grouped), 2)\n",
    "    nrows = int(np.ceil(grouped.ngroups/ncols))\n",
    "\n",
    "    # If you don't supply outer_i, we take care of everything\n",
    "    if outer_i is None:\n",
    "        fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8*ncols,5*nrows))\n",
    "        if not isinstance(axes, np.ndarray):\n",
    "            axes = np.array([axes])\n",
    "    else:\n",
    "        inner = mpl.gridspec.GridSpecFromSubplotSpec(nrows, ncols,\n",
    "                    subplot_spec=outer_i, wspace=0.1, hspace=0.1)\n",
    "        \n",
    "        #np.array([[\"{},{}\".format(x,y) for y in range(ncols)] for x in range(nrows)])\n",
    "        axes = np.array([plt.Subplot(fig, inner[j]) for j in range(nrows*ncols)])\n",
    "        [fig.add_subplot(ax) for ax in axes]\n",
    "\n",
    "    # Plot each subplot\n",
    "    first_legend = add_legend\n",
    "    for (key, ax) in zip(grouped.groups.keys(), axes.flatten()):\n",
    "        gp = grouped.get_group(key)\n",
    "        gp.columns= gp.columns.droplevel('Units')\n",
    "        gp.index.name = ''\n",
    "        \n",
    "        # Sort by max absolute difference\n",
    "        gp = gp.loc[gp.apply(lambda row: max(row) - min(row), axis=1)\n",
    "                      .sort_values(ascending=False).index]\n",
    "        gp.plot(kind='bar', ax=ax)\n",
    "        if key == 'GJ':\n",
    "            title = \"Energy (GJ)\"\n",
    "        elif key == 'm3':\n",
    "            title = \"Water (m3)\"\n",
    "        else:\n",
    "            # shouldn't happen\n",
    "            title = key\n",
    "            \n",
    "        # Add labels with fontsize\n",
    "        ax.set_title(title, fontsize=fontsize+2)\n",
    "        ax.set_ylabel(key, fontsize=fontsize)\n",
    "        # Set tick size\n",
    "        for tick in ax.xaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(fontsize)\n",
    "            tick.label.set_rotation(45)\n",
    "        for tick in ax.yaxis.get_major_ticks():\n",
    "            tick.label.set_fontsize(fontsize)\n",
    "            \n",
    "        # Add % difference if any\n",
    "        for i, x in enumerate(ax.get_xticklabels()):\n",
    "            # Return 'Heating', 'Cooling', etc\n",
    "            idx = x.get_text()\n",
    "\n",
    "            # Loop on each successive versions\n",
    "            for k in range(len(gp.columns)-1):\n",
    "                v_old = gp.loc[idx].iloc[k]\n",
    "                v_new = gp.loc[idx].iloc[k+1]\n",
    "                if abs(v_new - v_old) > 0:\n",
    "                    pct = (v_new - v_old) / v_old\n",
    "\n",
    "                    if v_old > v_new:\n",
    "                        # Base on the first bar\n",
    "                        rect = ax.patches[i+k*len(ax.patches) // len(gp.columns)]\n",
    "                        # Offset needed to be at mid between both bars\n",
    "                        x_offset = rect.get_width()\n",
    "                    else:\n",
    "                        # Based on second bar\n",
    "                        rect = ax.patches[i+(k+1)*len(ax.patches) // len(gp.columns)]\n",
    "                        x_offset = 0\n",
    "\n",
    "                    ax.annotate(xy=(rect.get_x() + x_offset, rect.get_height()+0.05),\n",
    "                                xytext=(15*(2*k-1),20), textcoords='offset points',\n",
    "                                s=\"{:.2%}\".format(pct),\n",
    "                                ha='center', va='bottom',\n",
    "                                fontweight='normal',\n",
    "                                fontsize=fontsize-2, color='k',\n",
    "                                arrowprops=dict(arrowstyle=\"->\",\n",
    "                                connectionstyle=\"arc3\"))\n",
    "        \n",
    "        # Display legend or not\n",
    "        if not first_legend:\n",
    "            ax.legend().set_visible(False)\n",
    "        else:\n",
    "            ax.legend()\n",
    "        first_legend = False\n",
    "            \n",
    "    sns.despine()\n",
    "    \n",
    "    # Title\n",
    "    title = \"End Use for {}\".format(test)\n",
    "    # fig.suptitle(title)\n",
    "    axes[0].annotate(title,\n",
    "                     xy=(0.5*ncols, 1.0), xycoords='axes fraction',\n",
    "                     xytext=(0, 20), textcoords='offset points',\n",
    "                     va='bottom', ha='center',\n",
    "                     fontsize=fontsize+4, fontweight='bold',\n",
    "                     )\n",
    "    if outer_i is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test = 'centralheatpumpsystem.rb'\n",
    "df_all_end_use = parse_before_after_enduse(test)\n",
    "plot_end_use_diff(df_all_end_use, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_absolute_difference(df_all_end_use, is_incremental=True):\n",
    "    \"\"\"\n",
    "    Computes the absolute difference in (GJ/m3).\n",
    "    If is_incremental, compares from one version to the next\n",
    "        eg: returns [Transition - 2.4.2] and '2.4.3 - Transition')\n",
    "    if false, compares to the oldest one\n",
    "        eg: returns [Transition - 2.4.2] and '2.4.3 - 2.4.2')\n",
    "\n",
    "    Args:\n",
    "    ------\n",
    "    * df_all_end_use (pd.DataFrame): dataframe from parse_before_after_enduse\n",
    "    * is_incremental (bool): compare each version to the previous version\n",
    "        or to the oldest one\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    * abs_diff (pd.DataFrame)\n",
    "    * html_abs = HTML object\n",
    "    \n",
    "    \"\"\"\n",
    "    # Sort in the right order\n",
    "    cols_in_order = [x for x in [OLD_OS_INFO['OS_VERSION'],\n",
    "                                 TRANSITION_INFO['OS_VERSION'],\n",
    "                                 NEW_OS_INFO['OS_VERSION']] \n",
    "                     if x in df_all_end_use.columns]\n",
    "        \n",
    "    abs_diff = df_all_end_use.copy()\n",
    "    for i, col in enumerate(cols_in_order[1:]):\n",
    "        if is_incremental:\n",
    "            k = i\n",
    "        else:\n",
    "            k = 0\n",
    "        abs_diff[col] = df_all_end_use[col] - df_all_end_use[cols_in_order[k]]\n",
    "    abs_diff = abs_diff[cols_in_order[1:]]\n",
    "    \n",
    "    abs_diff = (abs_diff.replace(0, np.nan)\n",
    "                        .dropna(how='all', axis=0)\n",
    "                        .dropna(how='all', axis=1))\n",
    "    \n",
    "    if is_incremental:\n",
    "        ann = \"<strong>Comparing from one version to the next</strong>\"\n",
    "    else:\n",
    "        ann = \"<strong>Comparing each version to {}</strong>\".format(cols_in_order[0])\n",
    "    if abs_diff.empty:\n",
    "        # print(\"There are ZERO absolute differences for {}\".format(test))\n",
    "        html = HTML('<p>{}</p>\\n<p style=\"font-size: 18px; text-align: center\">'\n",
    "                    'There are <strong>ZERO</strong> absolute differences '\n",
    "                    'for {}</p>'.format(ann, test))\n",
    "    else:\n",
    "        html = (abs_diff.style.set_table_styles(styles)\n",
    "                 .set_caption(\"Absolute diff for {}\\n{}\".format(test, ann))\n",
    "                 .format(lambda x: \"{:.0f}\".format(x) if not np.isnan(x) else '-'))\n",
    "        # display(html)\n",
    "    return abs_diff, html\n",
    "\n",
    "def table_percent_difference_by_end_use_and_fuel(df_all_end_use,\n",
    "                                                 is_incremental=True):\n",
    "    \"\"\"\n",
    "    Computes the percentage difference in between the old and the new for each\n",
    "    end use and fuel.\n",
    "    \n",
    "    eg: Heating Electricity % is calculated as\n",
    "        (heating-electricity-kbtu-new) - (heating-electricity-kbtu-old)\n",
    "        / (heating-electricity-kbtu-old)\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * df_all_end_use (pd.DataFrame): dataframe from parse_before_after_enduse\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    * pct_diff (pd.DataFrame)\n",
    "    * html_diff = HTML object\n",
    "    \"\"\"\n",
    "    # Sort in the right order\n",
    "    cols_in_order = [x for x in [OLD_OS_INFO['OS_VERSION'],\n",
    "                                 TRANSITION_INFO['OS_VERSION'],\n",
    "                                 NEW_OS_INFO['OS_VERSION']] \n",
    "                     if x in df_all_end_use.columns]\n",
    "        \n",
    "    pct_diff = df_all_end_use.copy()\n",
    "    for i, col in enumerate(cols_in_order[1:]):\n",
    "        if is_incremental:\n",
    "            k = i\n",
    "        else:\n",
    "            k = 0\n",
    "        pct_diff[col] = (df_all_end_use[col] - df_all_end_use[cols_in_order[k]]) / df_all_end_use[cols_in_order[k]]\n",
    "\n",
    "    pct_diff = pct_diff[cols_in_order[1:]]\n",
    "    \n",
    "    pct_diff = (pct_diff.replace(0, np.nan)\n",
    "                        .dropna(how='all', axis=0)\n",
    "                        .dropna(how='all', axis=1))\n",
    "    \n",
    "    if is_incremental:\n",
    "        ann = \"<strong>Comparing from one version to the next</strong>\"\n",
    "    else:\n",
    "        ann = \"<strong>Comparing each version to {}</strong>\".format(cols_in_order[0])\n",
    "    \n",
    "    if pct_diff.empty:\n",
    "        # print(\"There are ZERO percentage differences for {}\".format(test))\n",
    "        html = HTML('<p>{}</p><p style=\"font-size: 18px; text-align: center\">'\n",
    "                    'There are <strong>ZERO</strong> percentage differences '\n",
    "                    'for {}</p>'.format(ann, test))\n",
    "    else:\n",
    "        html = (pct_diff.style.set_table_styles(styles)\n",
    "                 .set_caption(\"Relative individual % diff for each end use and\"\n",
    "                              \" fuel for '{}'\\n{}\".format(test, ann))\n",
    "                 .format(lambda x: \"{:.2%}\".format(x) if not np.isnan(x) else '-'))\n",
    "        # display(html)\n",
    "    return pct_diff, html\n",
    "\n",
    "def table_percent_difference_of_total(df_all_end_use, is_incremental=True):\n",
    "    \"\"\"\n",
    "    Computes the percentage difference in between the old and the new for each\n",
    "    type Water or GJ.\n",
    "    \n",
    "    eg: Heating % is calculated as\n",
    "        sum(heating-GJ-each-fuel-new) - sum(heating-GJ-each-fueld-old)\n",
    "        / sum(all_GJ)\n",
    "    \n",
    "    Args:\n",
    "    ------\n",
    "    * df_all_end_use (pd.DataFrame): dataframe from parse_before_after_enduse\n",
    "    * is_incremental (bool): compare each version to the previous version\n",
    "        or to the oldest one\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    * percentage_of_total (pd.DataFrame)\n",
    "    * html_tot = HTML object\n",
    "  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort in the right order\n",
    "    cols_in_order = [x for x in [OLD_OS_INFO['OS_VERSION'],\n",
    "                                 TRANSITION_INFO['OS_VERSION'],\n",
    "                                 NEW_OS_INFO['OS_VERSION']] \n",
    "                     if x in df_all_end_use.columns]\n",
    "\n",
    "    concat_dict = {}\n",
    "    for i, col in enumerate(cols_in_order[1:]):\n",
    "        if is_incremental:\n",
    "            k = i\n",
    "        else:\n",
    "            k = 0\n",
    "        sum_old = (df_all_end_use[cols_in_order[k]]\n",
    "                   .groupby(level='Units', axis=1).sum().sum())\n",
    "        abs_diff_end_use = ((df_all_end_use[col] \n",
    "                            - df_all_end_use[cols_in_order[k]])\n",
    "                            .stack(0)\n",
    "                            .groupby(level='EndUse').sum())\n",
    "\n",
    "        percentage_of_total = (abs_diff_end_use / sum_old)\n",
    "        d = {'GJ': 'Energy', 'm3': 'Water'}\n",
    "        percentage_of_total.columns = pd.MultiIndex.from_tuples([(d[x], x) \n",
    "                                                                 for x in percentage_of_total.columns],\n",
    "                                                                names=['Type', 'Units'])\n",
    "        concat_dict[col] = percentage_of_total\n",
    "    \n",
    "    percentage_of_total = pd.concat(concat_dict, axis=1)[cols_in_order[1:]]\n",
    "    # Drop end uses where we have nothing\n",
    "    percentage_of_total = (percentage_of_total.reindex(df_all_end_use.index)\n",
    "                                               .replace(0, np.nan)\n",
    "                                               .dropna(how='all', axis=0)\n",
    "                           )\n",
    "\n",
    "    # drop Fuel Type (units) where none of the versions have a change\n",
    "    sum_by_type =  percentage_of_total.groupby(level='Units', axis=1).sum().sum()\n",
    "    percentage_of_total.loc[:,\n",
    "                            (percentage_of_total.columns\n",
    "                             .get_level_values('Units')\n",
    "                             .isin(sum_by_type.index[sum_by_type != 0]))]\n",
    "    if is_incremental:\n",
    "        ann = \"<strong>Comparing from one version to the next</strong>\"\n",
    "    else:\n",
    "        ann = \"<strong>Comparing each version to {}</strong>\".format(cols_in_order[0])\n",
    "    \n",
    "    if percentage_of_total.empty:\n",
    "        # print(\"There are ZERO percentage differences for {}\".format(test))\n",
    "        html = HTML('<p>{}</p><p style=\"font-size: 18px; text-align: center\">'\n",
    "                    'There are <strong>ZERO</strong> percentage differences '\n",
    "                    'for {}</p>'.format(ann, test))\n",
    "    else:\n",
    "        html = (percentage_of_total.style.set_table_styles(styles)\n",
    "                 .set_caption(\"% diff of total GJ/m3 {}\\n{}\".format(test, ann))\n",
    "                 .format(lambda x: \"{:.2%}\".format(x) if not np.isnan(x) else '-'))\n",
    "        # display(html)\n",
    "    return percentage_of_total, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_for_test(test, is_incremental=True,\n",
    "                    old_os=True, transition=True, new_os=True,\n",
    "                    plot_if_no_diff=True, add_legend=True,\n",
    "                    display_tables=False,\n",
    "                    plot_heatmap=False, heatmap_as_pct_of_total=False,\n",
    "                    outer_i=None, fig=None):\n",
    "    \"\"\"\n",
    "    High level method to investigate differences\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    * test (str): test name, eg 'centralheatpumpsystem.rb\n",
    "    * is_incremental (bool): compare each version to the previous version\n",
    "        or to the oldest one\n",
    "\n",
    "    * old_os, transition, new_os (bool): whether to include these versions\n",
    "    Note that it relies on the respective global dictionaries\n",
    "    OLD_OS_INFO, TRANSITION_INFO, NEW_OS_INFO\n",
    "    * display_tables (bool): if true, shows `table_absolute_difference`\n",
    "        and `table_percent_difference_table`\n",
    "    * plot_if_no_diff (bool): if there are no difference, whether to show \n",
    "        `plot_end_use_diff` anyways or not\n",
    "    * gs (matplotlib GridSpec): Pass one if you want to organize the figures\n",
    "        in a given layout, otherwise a new plot is created\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    * fig (matplotlib.figure)\n",
    "    \n",
    "    Can display requested things on the fly too\n",
    "    \n",
    "    \"\"\"\n",
    "    has_diff = False\n",
    "    \n",
    "    df_all_end_use = parse_before_after_enduse(test,\n",
    "                                               old_os=old_os,\n",
    "                                               transition=transition,\n",
    "                                               new_os=new_os)\n",
    "    abs_diff, html_abs = table_absolute_difference(df_all_end_use, is_incremental)\n",
    "    # display(html_abs)\n",
    "    if not abs_diff.empty:\n",
    "        has_diff = True\n",
    "        if display_tables:\n",
    "            pct_diff, html_pct = table_percent_difference_by_end_use_and_fuel(df_all_end_use, is_incremental)\n",
    "            percentage_of_total, html_tot = table_percent_difference_of_total(df_all_end_use, is_incremental)\n",
    "\n",
    "            display(HTML(\"\"\"\n",
    "            <div style='display: grid; grid-template-columns: 1fr 1fr 1fr; grid-column-gap: 10px;'>\n",
    "                <div style='align-self: center; width: '> {html_abs} </div>\n",
    "                <div style='align-self: center;'> {html_pct} </div>\n",
    "                <div style='align-self: center;'> {html_tot} </div>\n",
    "            </div>\"\"\".format(html_abs=html_abs.render(),\n",
    "                             html_pct=html_pct.render(),\n",
    "                             html_tot=html_tot.render())))\n",
    "        \n",
    "    else:\n",
    "        display(html_abs)\n",
    "    \n",
    "    if (has_diff | plot_if_no_diff):\n",
    "        plot_end_use_diff(df_all_end_use=df_all_end_use, test=test,\n",
    "                          outer_i=outer_i, fig=fig,\n",
    "                          add_legend=add_legend)\n",
    "        \n",
    "    if has_diff & plot_heatmap:\n",
    "        if heatmap_as_pct_of_total:\n",
    "            plot_heatmap_pct_diff(test=test, pct_diff=percentage_of_total,\n",
    "                                  is_incremental=is_incremental,\n",
    "                                  as_pct_of_total=True)\n",
    "        else:\n",
    "            plot_heatmap_pct_diff(test=test, pct_diff=pct_diff,\n",
    "                                  is_incremental=is_incremental,\n",
    "                                  as_pct_of_total=False)\n",
    "        \n",
    "def plot_heatmap_pct_diff(test, is_incremental=False,\n",
    "                          pct_diff=None, df_all_end_use=None,\n",
    "                          ax=None, figsize=None, short_title=False,\n",
    "                          as_pct_of_total=False, vmax=None):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of percentage difference. It will show the xlabels\n",
    "    as \"Fuel\" only if one unit, if more than one it's \"Fuel-Units\"\n",
    "    \n",
    "    Args:\n",
    "    -----\n",
    "    * test (str): test name\n",
    "    * pct_diff (pd.DataFrame): from `table_percent_difference_table(both_end_use)`\n",
    "        If not supplied, it is recomputed\n",
    "        * as_pct_of_total (bool): if True, calls `table_percent_difference_of_total`\n",
    "        otherwise calls `table_percent_difference_by_end_use_and_fuel`\n",
    "    * df_all_end_use (pd.DataFrame): from `parse_before_after_enduse(test)`\n",
    "        If pct_diff is not supplied, it uses this dataframe to recompute pct_diff\n",
    "        If also not supplied, it is recomputed\n",
    "    * ax (matplotlib.axes._subplots.AxesSubplot): The axis on which to plot,\n",
    "        pass None to create a new figure\n",
    "    * figsize (tuple of int): force a given figure size\n",
    "        pass None to autocalculate\n",
    "    * short_title (bool): display only the test name or also with versions\n",
    "    * vmax (float, typically between 0 and 1): the maximum for the colorbar\n",
    "        if None, defaults to 0.25 (25%) is as_pct_of_total is False, and\n",
    "        0.05 (5%) if as_pct_of_total is True\n",
    "    Returns:\n",
    "    --------\n",
    "    None, plots the heatmap\n",
    "    \"\"\"\n",
    "    if vmax is None:\n",
    "        if as_pct_of_total:\n",
    "            # Colorbar goes from 0 (yellow) to 5% (red)\n",
    "            vmax = 0.05\n",
    "        else:\n",
    "            vmax = 0.25\n",
    "    \n",
    "    # Modularity in arguments, compute only what's needed\n",
    "    if pct_diff is None:\n",
    "        if df_all_end_use is None:\n",
    "            df_all_end_use = parse_before_after_enduse(test)\n",
    "        if as_pct_of_total:\n",
    "            pct_diff, _ = table_percent_difference_of_total(df_all_end_use=df_all_end_use,\n",
    "                                                            is_incremental=is_incremental)\n",
    "        else:\n",
    "            pct_diff, _ = table_percent_difference_by_end_use_and_fuel(df_all_end_use=df_all_end_use,\n",
    "                                                                       is_incremental=is_incremental)\n",
    "\n",
    "    show_plot = False\n",
    "    if ax is None:\n",
    "        show_plot = True\n",
    "        if figsize is None:\n",
    "            w = min(pct_diff.shape[0], 16)\n",
    "            h = pct_diff.shape[0] * w / (3*pct_diff.shape[1])\n",
    "        else:\n",
    "            w = figsize[0]\n",
    "            h = figsize[1]\n",
    "        fig, ax = plt.subplots(figsize=(w, h))\n",
    "\n",
    "    fmt = lambda x,pos: '{:.0%}'.format(x)\n",
    "\n",
    "    toplot = pct_diff.copy()\n",
    "    if len(toplot.columns.get_level_values('Units').unique()) == 1:\n",
    "        toplot.columns = toplot.columns.droplevel('Units')\n",
    "\n",
    "    sns.heatmap(toplot.abs(),\n",
    "                ax=ax, cmap='YlOrRd',\n",
    "                vmin=0, vmax=vmax,\n",
    "                cbar_kws={'format': mpl.ticker.FuncFormatter(fmt)},\n",
    "                annot=toplot, fmt='.2%')\n",
    "    if short_title:\n",
    "        title = test\n",
    "    else:\n",
    "        if as_pct_of_total:\n",
    "            title = (\"Percent difference of total GJ/m3 by End Use for test \"\n",
    "                     \"'{}'\".format(test))\n",
    "        else:\n",
    "            title = (\"Relative Individual % diff for each End Use / Fuel for test \"\n",
    "                     \"'{}'\".format(test))\n",
    "        if is_incremental:\n",
    "            title += '\\nComparing from one version to the next'\n",
    "        else:\n",
    "            title += '\\nComparing each to the oldest version ({})'.format(OLD_OS_INFO['OS_VERSION'])\n",
    "    ax.set_title(title)\n",
    "    if show_plot:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hover(hover_color=\"#ffff99\"):\n",
    "    return dict(selector=\"tr:hover\",\n",
    "                props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "\n",
    "styles = [\n",
    "    hover(),\n",
    "    dict(selector=\"th\", props=[(\"font-size\", \"110%\"),\n",
    "                               (\"text-align\", \"center\")]),\n",
    "    dict(selector=\"td\", props=[(\"text-align\", \"center\")]),\n",
    "    dict(selector=\"caption\", props=[(\"caption-side\", \"bottom\"),\n",
    "                                    (\"text-align\", \"center\")])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make graph centered on page\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has differences, but no water\n",
    "test = 'foundation_kiva.osm'\n",
    "report_for_test(test, is_incremental=False,\n",
    "                old_os=True, transition=True, new_os=True,\n",
    "                plot_if_no_diff=True, display_tables=True,\n",
    "                plot_heatmap=True, heatmap_as_pct_of_total=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Zero difference, but has water\n",
    "test = 'water_heaters.rb'\n",
    "report_for_test(test, is_incremental=False,\n",
    "                old_os=True, transition=True, new_os=True,\n",
    "                plot_if_no_diff=True, display_tables=True, \n",
    "                plot_heatmap=True, heatmap_as_pct_of_total=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has differences in both energy and water\n",
    "test = 'plenums.rb'\n",
    "# Let's plot non incremental\n",
    "report_for_test(test, is_incremental=False,\n",
    "                old_os=True, transition=True, new_os=True,\n",
    "                plot_if_no_diff=True, display_tables=True,\n",
    "                plot_heatmap=True, heatmap_as_pct_of_total=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'baseline_sys07.rb'\n",
    "df_all_end_use = parse_before_after_enduse(test,\n",
    "                                           old_os=True, transition=True,\n",
    "                                           new_os=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show absolute values for only fuel/end use that have a value\n",
    "df_all_end_use.replace(0, np.nan).dropna(how='all', axis=0).dropna(how='all', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_diff, html = table_percent_difference_by_end_use_and_fuel(df_all_end_use)\n",
    "display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't supply pct_diff, it will be computed again\n",
    "# if also you don't supply both_end_use, it will be computed again\n",
    "# Do notice the is_incremental keyword again...\n",
    "plot_heatmap_pct_diff(test, pct_diff=None,\n",
    "                      is_incremental=True,\n",
    "                      df_all_end_use=None,\n",
    "                      figsize=(16,9), short_title=False,\n",
    "                      # Switch as_pct_of_total to see the difference\n",
    "                      as_pct_of_total=True, vmax=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tests - one per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only really care about differences between Transition and new OS\n",
    "s_diff = df_diff.iloc[:, -1]\n",
    "s_diff.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_for_largest_n = 6\n",
    "\n",
    "add_legend=True\n",
    "for test in s_diff.nlargest(report_for_largest_n).index:\n",
    "    report_for_test(test, plot_if_no_diff=True, display_tables=False, \n",
    "                    add_legend=True)\n",
    "    add_legend=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tests - in a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_diff.nlargest(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_for_largest_n = 10\n",
    "\n",
    "outer_ncols = 2\n",
    "outer_nrows = int(np.ceil(report_for_largest_n/outer_ncols))\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4*outer_nrows))\n",
    "outer = mpl.gridspec.GridSpec(outer_nrows, outer_ncols, wspace=0.1, hspace=0.5)\n",
    "\n",
    "add_legend = True\n",
    "for i, test in enumerate(s_diff.nlargest(report_for_largest_n).index):\n",
    "    df_all_end_use = parse_before_after_enduse(test)\n",
    "    plot_end_use_diff(df_all_end_use=df_all_end_use, test=test, \n",
    "                      outer_i=outer[i], \n",
    "                      fig=fig, fontsize=7, add_legend=add_legend)\n",
    "    add_legend = False\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Tests - heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "report_for_largest_n = 10\n",
    "\n",
    "ncols = 2\n",
    "nrows = int(np.ceil(report_for_largest_n/outer_ncols))\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 4*outer_nrows))\n",
    "\n",
    "add_legend = True\n",
    "for test, ax in zip(s_diff.nlargest(report_for_largest_n).index, axes.flatten()):\n",
    "    # Switch as_pct_of_total, force vmax (max of colorbar) if you want\n",
    "    plot_heatmap_pct_diff(test, ax=ax,\n",
    "                          is_incremental=True,\n",
    "                          short_title=True,\n",
    "                          as_pct_of_total=True, vmax=None)\n",
    "    \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strip output cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local import\n",
    "import os\n",
    "import glob as gb\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#filelist = gb.glob('*.html')\n",
    "filelist = ['Analysis_from_2.4.2(8.8.0)_to_2.4.3(8.9.0).html']\n",
    "\n",
    "for s_path in filelist:\n",
    "    print(s_path)\n",
    "    \n",
    "    save_path = \"{}_stripped.html\".format(os.path.splitext(s_path)[0])\n",
    "    print(\"Deleting input cells and warnings\")\n",
    "    with open(s_path,\"r+\") as htmlDoc:\n",
    "        soup = BeautifulSoup(htmlDoc, \"lxml\")\n",
    "        # Get input divs\n",
    "        tg = soup.find_all(attrs={\"class\": \"input\"})\n",
    "        # Add input stderr (warnings and errors)\n",
    "        tg += soup.find_all(attrs={\"class\": \"output_stderr\"})\n",
    "        # Replace with nothing\n",
    "        for i in range(len(tg)):\n",
    "            tg[i].replace_with(\"\")\n",
    "\n",
    "    # Prettify\n",
    "    html = soup.prettify(\"utf-8\")\n",
    "    #exportpath = os.path.splitext(htmlpath)[0]+'-noinput'+os.path.splitext(htmlpath)[1]\n",
    "\n",
    "    # Write\n",
    "    with open(save_path, \"wb\") as file:\n",
    "        file.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_path = filelist[0]\n",
    "with open(s_path,\"r+\") as htmlDoc:\n",
    "    soup = BeautifulSoup(htmlDoc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "810px",
    "left": "0px",
    "right": "1643px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
